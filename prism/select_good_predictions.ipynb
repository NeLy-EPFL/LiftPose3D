{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import cv2\n",
    "from math import atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "th1 = 0.95 #confidence threshold\n",
    "th2 = 10 #max L-R discrepancy in x coordinate\n",
    "\n",
    "home_dir = '/data/LiftFly3D/prism/'\n",
    "data_dir = '/mnt/NAS/SG/prism_data/'\n",
    "scorer_bottom = 'DLC_resnet50_jointTrackingDec13shuffle1_200000'\n",
    "scorer_side = 'DLC_resnet50_sideJointTrackingDec17shuffle1_200000'\n",
    "\n",
    "#joints whose confidence to consider\n",
    "leg_tips = ['tarsus tip front L', 'tarsus tip mid L', 'tarsus tip back L',\n",
    "          'tarsus tip front R', 'tarsus tip mid R', 'tarsus tip back R']\n",
    "\n",
    "crop_positions = ['/bottom_view/videos/crop_loc_191125_PR_Fly1_001_prism.txt',\n",
    "                  '/bottom_view/videos/crop_loc_191125_PR_Fly1_002_prism.txt',\n",
    "                  '/bottom_view/videos/crop_loc_191125_PR_Fly1_003_prism.txt',\n",
    "                  '/bottom_view/videos/crop_loc_191125_PR_Fly1_004_prism.txt',\n",
    "                  '/bottom_view/videos/crop_loc_191125_PR_Fly2_001_prism.txt',\n",
    "                  '/bottom_view/videos/crop_loc_191125_PR_Fly2_002_prism.txt',\n",
    "                  '/bottom_view/videos/crop_loc_191125_PR_Fly2_003_prism.txt',\n",
    "                  '/bottom_view/videos/crop_loc_191125_PR_Fly2_004_prism.txt']\n",
    "\n",
    "videos_side = ['side_view/videos/video_191125_PR_Fly1_001_prism',\n",
    "               'side_view/videos/video_191125_PR_Fly1_002_prism',\n",
    "               'side_view/videos/video_191125_PR_Fly1_003_prism',\n",
    "               'side_view/videos/video_191125_PR_Fly1_004_prism',\n",
    "               'side_view/videos/video_191125_PR_Fly2_001_prism',\n",
    "               'side_view/videos/video_191125_PR_Fly2_002_prism',\n",
    "               'side_view/videos/video_191125_PR_Fly2_003_prism',\n",
    "               'side_view/videos/video_191125_PR_Fly2_004_prism']\n",
    "\n",
    "videos_bottom =  ['bottom_view/videos/video_191125_PR_Fly1_001_prism',\n",
    "                  'bottom_view/videos/video_191125_PR_Fly1_002_prism',\n",
    "                  'bottom_view/videos/video_191125_PR_Fly1_003_prism',\n",
    "                  'bottom_view/videos/video_191125_PR_Fly1_004_prism',\n",
    "                  'bottom_view/videos/video_191125_PR_Fly2_001_prism',\n",
    "                  'bottom_view/videos/video_191125_PR_Fly2_002_prism',\n",
    "                  'bottom_view/videos/video_191125_PR_Fly2_003_prism',\n",
    "                  'bottom_view/videos/video_191125_PR_Fly2_004_prism']\n",
    "\n",
    "images_side = ['191125_PR/Fly1/001_prism/behData/images/side_view_prism_data_191125_PR_Fly1/',\n",
    "               '191125_PR/Fly1/002_prism/behData/images/side_view_prism_data_191125_PR_Fly1/',\n",
    "               '191125_PR/Fly1/003_prism/behData/images/side_view_prism_data_191125_PR_Fly1/',\n",
    "               '191125_PR/Fly1/004_prism/behData/images/side_view_prism_data_191125_PR_Fly1/',\n",
    "               '191125_PR/Fly2/001_prism/behData/images/side_view_prism_data_191125_PR_Fly2/',\n",
    "               '191125_PR/Fly2/002_prism/behData/images/side_view_prism_data_191125_PR_Fly2/',\n",
    "               '191125_PR/Fly2/003_prism/behData/images/side_view_prism_data_191125_PR_Fly2/',\n",
    "               '191125_PR/Fly2/004_prism/behData/images/side_view_prism_data_191125_PR_Fly2/']\n",
    "\n",
    "images_bottom =  ['191125_PR/Fly1/001_prism/behData/images/bottom_view_prism_data_191125_PR_Fly1/',\n",
    "                  '191125_PR/Fly1/002_prism/behData/images/bottom_view_prism_data_191125_PR_Fly1/',\n",
    "                  '191125_PR/Fly1/003_prism/behData/images/bottom_view_prism_data_191125_PR_Fly1/',\n",
    "                  '191125_PR/Fly1/004_prism/behData/images/bottom_view_prism_data_191125_PR_Fly1/',\n",
    "                  '191125_PR/Fly2/001_prism/behData/images/bottom_view_prism_data_191125_PR_Fly2/',\n",
    "                  '191125_PR/Fly2/002_prism/behData/images/bottom_view_prism_data_191125_PR_Fly2/',\n",
    "                  '191125_PR/Fly2/003_prism/behData/images/bottom_view_prism_data_191125_PR_Fly2/',\n",
    "                  '191125_PR/Fly2/004_prism/behData/images/bottom_view_prism_data_191125_PR_Fly2/']\n",
    "\n",
    "assert len(videos_side)==len(videos_bottom), 'Number of video files must be the same from side and bottom!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_crop_pos(file):\n",
    "    f=open(file, \"r\")\n",
    "    contents =f.readlines()\n",
    "    pos = []\n",
    "    for i in range(4,len(contents)):\n",
    "        line = contents[i][:-1].split(' ')\n",
    "        pos.append(int(line[1]))\n",
    "        \n",
    "    return pos\n",
    "\n",
    "\n",
    "def orientation(img):\n",
    "    #_, img_th = cv2.threshold(img, 250, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    img_th = img.copy()\n",
    "    img_th[img_th < 130] = 0 # was 140\n",
    "    # Find all the contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(img_th, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    if len(contours) < 1 : return None\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Calculate the area of each contour\n",
    "        area = cv2.contourArea(contour)\n",
    "        # Ignore contours that are too small or too large\n",
    "        if area > 10000:\n",
    "            break\n",
    "\n",
    "    # Find the orientation of each shape\n",
    "    img_pts = np.empty((len(contour), 2), dtype=np.float64)\n",
    "    img_pts[:,0], img_pts[:,1] = contour[:,0,0], contour[:,0,1]\n",
    "\n",
    "    # PCA analysis\n",
    "    mean = np.empty((0))\n",
    "    _, eigenvectors, _ = cv2.PCACompute2(img_pts, mean)\n",
    "\n",
    "    angle = atan2(eigenvectors[0,1], eigenvectors[0,0])\n",
    "    return angle\n",
    "\n",
    "\n",
    "def read_crop_pos(file):\n",
    "    f=open(file, \"r\")\n",
    "    contents =f.readlines()\n",
    "    im_file = []\n",
    "    x_pos = []\n",
    "    for i in range(4,len(contents)):\n",
    "        line = contents[i][:-1].split(' ')\n",
    "        im_file.append(line[0])\n",
    "        x_pos.append(line[1])\n",
    "        \n",
    "    return im_file, x_pos\n",
    "\n",
    "\n",
    "def center_and_align(pts2d, exp):\n",
    "    '''rotate align data'''\n",
    "    \n",
    "    #access corresponding image file\n",
    "    idx = pts2d.name \n",
    "    im_file, _ = read_crop_pos(home_dir + crop_positions[exp])\n",
    "    im_crop_bottom = cv2.imread(data_dir + images_bottom[exp] + im_file[idx],0)\n",
    "    \n",
    "    #get orientation and centre\n",
    "    angle = orientation(im_crop_bottom)\n",
    "    c = np.array(im_crop_bottom.shape)/2\n",
    "    \n",
    "    #rotate points\n",
    "    cos, sin = np.cos(angle), np.sin(angle)\n",
    "    R = np.array(((cos, -sin), (sin, cos)))    \n",
    "    tmp = pts2d.to_numpy().reshape(-1, 2)\n",
    "    tmp = np.matmul(tmp-c,R) + c   \n",
    "    pts2d.iloc[:] = tmp.reshape(-1,tmp.shape[0]*2).flatten()\n",
    "        \n",
    "    return pts2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for high quality frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:24<00:00, 33.03s/it]\n"
     ]
    }
   ],
   "source": [
    "index = []\n",
    "side = pd.DataFrame()\n",
    "bottom = pd.DataFrame()\n",
    "for i in tqdm(range(len(videos_side))):\n",
    "    _side = pd.read_hdf(home_dir + videos_side[i] + scorer_side + '.h5')\n",
    "    _bottom = pd.read_hdf(home_dir + videos_bottom[i] + scorer_bottom + '.h5')\n",
    "    \n",
    "    #drop scorer column label\n",
    "    _side = _side.droplevel('scorer',axis=1) \n",
    "    _bottom = _bottom.droplevel('scorer',axis=1) \n",
    "    \n",
    "    #split L and R (remove if we include flipping)\n",
    "    side_L_lk = _side.loc[:,(leg_tips[:3],'likelihood')]\n",
    "    side_R_lk = _side.loc[:,(leg_tips[3:],'likelihood')]\n",
    "    bottom_lk = _bottom.loc[:,(leg_tips,'likelihood')]\n",
    "    \n",
    "    #select for high likelihood frames\n",
    "    #mask = ((side_L_lk>th1).sum(1)==3) & ((bottom_lk>th1).sum(1)==6) #only flies pointing left\n",
    "    #mask = ((side_R_lk>th1).sum(1)==3) & ((bottom_lk>th1).sum(1)==6) #only flies pointing right\n",
    "    mask = ( ((side_L_lk>th1).sum(1)==3) | ((side_R_lk>th1).sum(1)==3) ) & ((bottom_lk>th1).sum(1)==6)\n",
    "    _side = _side[mask].dropna()\n",
    "    _bottom = _bottom[mask].dropna()\n",
    "    \n",
    "    #sometimes DLC mixes up limbs so take only those frames there the x coordinate matches on side and bottom views\n",
    "    diff_L = np.abs(_bottom.loc[:,(leg_tips[:3],'x')].values - _side.loc[:,(leg_tips[3:],'x')].values)\n",
    "    diff_R = np.abs(_bottom.loc[:,(leg_tips[3:],'x')].values - _side.loc[:,(leg_tips[:3],'x')].values)\n",
    "    mask = ((diff_L<th2).sum(1)==3) | ((diff_R<th2).sum(1)==3)\n",
    "    _side = _side[mask].dropna()\n",
    "    _bottom = _bottom[mask].dropna()\n",
    "    \n",
    "    #save indices for later\n",
    "    index.append(_bottom.index.values)\n",
    "    \n",
    "    assert _side.shape[0]==_bottom.shape[0], 'Number of rows must match in filtered data!'\n",
    "    \n",
    "    #flip left and right side due to prism reflection\n",
    "    cols = list(_side.columns)\n",
    "    half = int(len(cols)/2)\n",
    "    tmp = _bottom.loc[:,cols[:half]].values\n",
    "    _bottom.loc[:,cols[:half]] = _bottom.loc[:,cols[half:]].values\n",
    "    _bottom.loc[:,cols[half:]] = tmp\n",
    "    \n",
    "    #align horizontally\n",
    "    _bottom.loc[:,(slice(None),['x','y'])] = _bottom.loc[:,(slice(None),['x','y'])].apply(lambda x: center_and_align(x, i), axis=1)\n",
    "    \n",
    "    #rotate flies pointing right\n",
    "    theta = np.radians(180)\n",
    "    cos, sin = np.cos(theta), np.sin(theta)\n",
    "    R = np.array(((cos, -sin), (sin, cos)))\n",
    "    \n",
    "    side_R_lk = _side.loc[:,(leg_tips[3:],'likelihood')] #high confidence on R joints means fly points right\n",
    "    flip_idx = (side_R_lk>th1).sum(1)==3\n",
    "    \n",
    "    if np.sum(flip_idx) != 0:\n",
    "        tmp = _bottom.loc[flip_idx,(slice(None),['x','y'])].to_numpy()\n",
    "        tmp = np.reshape(tmp, [-1, 2])\n",
    "        mu = tmp.mean(axis=0)\n",
    "        tmp = np.matmul(tmp-mu,R) + mu\n",
    "        tmp = np.reshape( tmp, [-1, 60] )\n",
    "        _bottom.loc[flip_idx,(slice(None),['x','y'])] = tmp\n",
    "    \n",
    "    #also flip left and right side\n",
    "    #cols = list(_side.columns)\n",
    "    #half = int(len(cols)/2)\n",
    "    #tmp = _side.loc[flip_idx,cols[:half]].values\n",
    "    #_side.loc[flip_idx,cols[:half]] = _side.loc[flip_idx,cols[half:]].values\n",
    "    #_side.loc[flip_idx,cols[half:]] = tmp\n",
    "    #tmp = _bottom.loc[flip_idx,cols[:half]].values\n",
    "    #_bottom.loc[flip_idx,cols[:half]] = _bottom.loc[flip_idx,cols[half:]].values\n",
    "    #_bottom.loc[flip_idx,cols[half:]] = tmp\n",
    "\n",
    "    #convert & save to DF3D format\n",
    "    side_np = _side.loc[:,(slice(None),['x','y'])].to_numpy()\n",
    "    z = _side.loc[:,(slice(None),'y')].to_numpy()\n",
    "    side_np = np.stack((side_np[:,::2], side_np[:,1::2]), axis=2)\n",
    "\n",
    "    bottom_np = _bottom.loc[:,(slice(None),['x','y'])].to_numpy()\n",
    "    bottom_np = np.stack((bottom_np[:,::2], bottom_np[:,1::2]), axis=2)\n",
    "    \n",
    "    poses = {'points2d': np.stack((bottom_np, side_np), axis=0),\n",
    "             'points3d': np.concatenate((bottom_np, z[:,:,None]), axis=2),\n",
    "             'index':_side.index.values,\n",
    "             'flip_idx': np.array(flip_idx),\n",
    "             #'centroid': c\n",
    "            }\n",
    "    \n",
    "    #save\n",
    "    pickle.dump(poses,open(home_dir + videos_side[i].split('/')[-1][6:] + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(_bottom.shape[0]):\n",
    "    plt.scatter(poses['points2d'][0,i,:,0],poses['points2d'][0,i,:,1])\n",
    "    if i==50:\n",
    "        import sys\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(poses['points2d'][0,i,:15,0],poses['points2d'][0,i,:15,1])\n",
    "plt.scatter(poses['points2d'][0,i,15:,0],poses['points2d'][0,i,15:,1])\n",
    "plt.scatter(poses['points2d'][0,i,:15,0],275+280-poses['points2d'][0,i,:15,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "2       False\n",
       "3       False\n",
       "5       False\n",
       "6       False\n",
       "        ...  \n",
       "2538    False\n",
       "2539    False\n",
       "2540    False\n",
       "2542    False\n",
       "2544    False\n",
       "Length: 111, dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make joint video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "    \n",
    "def imgs_to_video(imgs, fps, out_path):\n",
    "    '''Write video from a list of images'''\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') #‘F’, ‘M’, ‘P’, ‘4’\n",
    "    out = cv2.VideoWriter(out_path, fourcc, fps, (imgs[0].shape[1], imgs[0].shape[0]))\n",
    "                          #imgs[0].shape[:2])\n",
    "    for img in imgs:\n",
    "        out.write(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    out.release()\n",
    "    \n",
    "                          \n",
    "def video_to_imgs(vid_path):\n",
    "    '''Convert video to a list of images'''\n",
    "    \n",
    "    cap = cv2.VideoCapture(vid_path)         \n",
    "    imgs = []            \n",
    "    while True:\n",
    "        flag, frame = cap.read()\n",
    "        if flag:                            \n",
    "            imgs.append(frame)       \n",
    "        else:\n",
    "            break        \n",
    "    \n",
    "    return imgs\n",
    "                                          \n",
    "    \n",
    "def concat_vids(vid_name):   \n",
    "     \n",
    "    cmd = 'ffmpeg -f concat -safe 0 -i videos.txt -c copy ' + vid_name\n",
    "    subprocess.call(cmd, shell=True)\n",
    "\n",
    "    \n",
    "def videos_to_concat(paths):\n",
    "    '''\n",
    "    Make a textfile with paths to videos to concatenate\n",
    "    '''\n",
    "    f = open('videos.txt','w+')\n",
    "    for i in paths:\n",
    "        f.write(\"file '\" + i + \"'\\r\\n\")\n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('create videos')\n",
    "paths = []\n",
    "for i in tqdm(range(len(videos_side))):       \n",
    "    #extract frames\n",
    "    frames = video_to_imgs(home_dir + videos_side[i] + scorer_side + '_labeled.mp4') #convert to frames\n",
    "    frames = [frames[j] for j in index[i]] #prune frames\n",
    "    paths.append(home_dir + 'side_' + str(i) + '.mp4') #save output video path for later\n",
    "    imgs_to_video(frames, 50, paths[i]) #convert back to video\n",
    "frames = [] #to free up memory \n",
    "    \n",
    "print('concatenate videos')\n",
    "videos_to_concat(paths)\n",
    "concat_vids(home_dir + 'side.mp4')\n",
    "    \n",
    "print('create videos')    \n",
    "paths = []\n",
    "for i in tqdm(range(len(videos_bottom))):    \n",
    "    #extract frames\n",
    "    frames = video_to_imgs(home_dir + videos_bottom[i] + scorer_bottom + '_labeled.mp4') #convert to frames\n",
    "    frames = [frames[j] for j in index[i]] #prune frames\n",
    "    paths.append(home_dir + 'bottom_' + str(i) + '.mp4') #save output video path for later\n",
    "    imgs_to_video(frames, 50, paths[i]) #convert back to video\n",
    "\n",
    "frames = [] #to free up memory    \n",
    "print('concatenate videos')\n",
    "videos_to_concat(paths)\n",
    "concat_vids(home_dir + 'bottom.mp4')    \n",
    "\n",
    "print('stack videos')\n",
    "ffmpeg_cmd = \"ffmpeg -i \" + home_dir + \"side.mp4 -i \" + home_dir + \"bottom.mp4 -filter_complex vstack=inputs=2 \" + home_dir + \"stacked.mp4\"\n",
    "subprocess.call(ffmpeg_cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
