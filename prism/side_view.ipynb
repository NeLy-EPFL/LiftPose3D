{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate. This function creates a new project with subdirectories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gosztolai/anaconda3/envs/DLC_env/lib/python3.6/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/LiftFly3D/prism/side_view\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task='sideJointTracking' # Enter the name of your experiment Task\n",
    "experimenter='PrismData' # Enter the name of the experimenter\n",
    "videofile_path = [\n",
    "    \"/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4\",\n",
    "    \"/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4\",\n",
    "    \"/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4\",\n",
    "    \"/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4\",\n",
    "    \"/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4\",\n",
    "    \"/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4\",\n",
    "    \"/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4\",\n",
    "    \"/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4\"\n",
    "]\n",
    "\n",
    "deeplabcut_dir = \"/data/LiftFly3D/prism/side_view/\"\n",
    "config_path = deeplabcut_dir + \"config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_new_project(task, experimenter, data_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) (algo=='uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "deeplabcut.extract_frames(config_path, 'automatic', 'kmeans', crop=False, userfeedback=True)\n",
    "# there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#'''\n",
    "%gui wx\n",
    "deeplabcut.label_frames(config_path)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "deeplabcut.train_network(config_path,\n",
    "                         displayiters=2000,\n",
    "                         saveiters=20000,\n",
    "                         maxiters=200000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(config_path, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-200000 for model /data/LiftFly3D/prism/side_view/dlc-models/iteration-0/sideJointTrackingDec17-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from /data/LiftFly3D/prism/side_view/dlc-models/iteration-0/sideJointTrackingDec17-trainset95shuffle1/train/snapshot-200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /data/LiftFly3D/prism/side_view/dlc-models/iteration-0/sideJointTrackingDec17-trainset95shuffle1/train/snapshot-200000\n",
      "  0%|          | 0/6022 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4\n",
      "Duration of video [s]:  240.88 , recorded with  25.0 fps!\n",
      "Overall # of frames:  6022  found with (before cropping) frame dimensions:  550 260\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6060it [00:44, 135.61it/s]                          \n",
      "  0%|          | 0/12320 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  6022\n",
      "Saving results in /data/LiftFly3D/prism/side_view/videos...\n",
      "Starting to analyze %  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4\n",
      "Duration of video [s]:  492.8 , recorded with  25.0 fps!\n",
      "Overall # of frames:  12320  found with (before cropping) frame dimensions:  550 260\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12423it [01:35, 130.26it/s]                           \n",
      "  0%|          | 0/7110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  12320\n",
      "Saving results in /data/LiftFly3D/prism/side_view/videos...\n",
      "Starting to analyze %  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4\n",
      "Duration of video [s]:  284.4 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7110  found with (before cropping) frame dimensions:  550 260\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7171it [00:55, 130.23it/s]                          \n",
      "  0%|          | 0/5775 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  7110\n",
      "Saving results in /data/LiftFly3D/prism/side_view/videos...\n",
      "Starting to analyze %  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4\n",
      "Duration of video [s]:  231.0 , recorded with  25.0 fps!\n",
      "Overall # of frames:  5775  found with (before cropping) frame dimensions:  550 260\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5814it [00:44, 129.50it/s]                          \n",
      "  0%|          | 0/4610 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  5775\n",
      "Saving results in /data/LiftFly3D/prism/side_view/videos...\n",
      "Starting to analyze %  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4\n",
      "Duration of video [s]:  184.4 , recorded with  25.0 fps!\n",
      "Overall # of frames:  4610  found with (before cropping) frame dimensions:  550 260\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4646it [00:36, 128.86it/s]                          \n",
      "  2%|▏         | 36/1829 [00:00<00:05, 338.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  4610\n",
      "Saving results in /data/LiftFly3D/prism/side_view/videos...\n",
      "Starting to analyze %  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4\n",
      "Duration of video [s]:  73.16 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1829  found with (before cropping) frame dimensions:  550 260\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1836it [00:13, 134.13it/s]                          \n",
      "  0%|          | 0/3418 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1829\n",
      "Saving results in /data/LiftFly3D/prism/side_view/videos...\n",
      "Starting to analyze %  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4\n",
      "Duration of video [s]:  136.72 , recorded with  25.0 fps!\n",
      "Overall # of frames:  3418  found with (before cropping) frame dimensions:  550 260\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3434it [00:26, 127.83it/s]                          \n",
      "  0%|          | 0/2616 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  3418\n",
      "Saving results in /data/LiftFly3D/prism/side_view/videos...\n",
      "Starting to analyze %  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4\n",
      "Duration of video [s]:  104.64 , recorded with  25.0 fps!\n",
      "Overall # of frames:  2616  found with (before cropping) frame dimensions:  550 260\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2626it [00:20, 128.70it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  2616\n",
      "Saving results in /data/LiftFly3D/prism/side_view/videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_sideJointTrackingDec17shuffle1_200000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(config_path,videofile_path, videotype='.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config_file = '/home/morales/Documents/Morales/fly_lane-DM-2019-02-19/config.yaml'\n",
    "crop_video = '/home/morales/Documents/Morales/MDN3_Screen/GFP/190315/161441_s0a0_p75/output_40fps_5.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "path_config_file = '/home/morales/Documents/Morales/fly_lane-DM-2019-02-19/config.yaml'\n",
    "crop_video = '/home/morales/Documents/Morales/MDN3_Screen/GFP/190315/161441_s0a0_p75/output_40fps_5.avi'\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file,[crop_video])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 46/6022 [00:00<00:13, 455.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /data/LiftFly3D/prism/side_view/videos ['/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4']\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4 and data.\n",
      "6022\n",
      "Duration of video [s]:  240.88 , recorded with  25.0 fps!\n",
      "Overall # of frames:  6022 with cropped frame dimensions:  550 260\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6022/6022 [00:13<00:00, 432.81it/s]\n",
      "  0%|          | 41/12320 [00:00<00:30, 398.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /data/LiftFly3D/prism/side_view/videos ['/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4']\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4 and data.\n",
      "12320\n",
      "Duration of video [s]:  492.8 , recorded with  25.0 fps!\n",
      "Overall # of frames:  12320 with cropped frame dimensions:  550 260\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12320/12320 [00:29<00:00, 421.27it/s]\n",
      "  1%|          | 39/7110 [00:00<00:18, 385.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /data/LiftFly3D/prism/side_view/videos ['/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4']\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4 and data.\n",
      "7110\n",
      "Duration of video [s]:  284.4 , recorded with  25.0 fps!\n",
      "Overall # of frames:  7110 with cropped frame dimensions:  550 260\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7110/7110 [00:17<00:00, 399.62it/s]\n",
      "  1%|          | 38/5775 [00:00<00:15, 373.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /data/LiftFly3D/prism/side_view/videos ['/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4']\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4 and data.\n",
      "5775\n",
      "Duration of video [s]:  231.0 , recorded with  25.0 fps!\n",
      "Overall # of frames:  5775 with cropped frame dimensions:  550 260\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5775/5775 [00:14<00:00, 407.08it/s]\n",
      "  1%|          | 39/4610 [00:00<00:11, 382.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /data/LiftFly3D/prism/side_view/videos ['/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4']\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4 and data.\n",
      "4610\n",
      "Duration of video [s]:  184.4 , recorded with  25.0 fps!\n",
      "Overall # of frames:  4610 with cropped frame dimensions:  550 260\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4610/4610 [00:11<00:00, 398.47it/s]\n",
      "  2%|▏         | 38/1829 [00:00<00:04, 377.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /data/LiftFly3D/prism/side_view/videos ['/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4']\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4 and data.\n",
      "1829\n",
      "Duration of video [s]:  73.16 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1829 with cropped frame dimensions:  550 260\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1829/1829 [00:04<00:00, 395.24it/s]\n",
      "  1%|          | 41/3418 [00:00<00:08, 407.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /data/LiftFly3D/prism/side_view/videos ['/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4']\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4 and data.\n",
      "3418\n",
      "Duration of video [s]:  136.72 , recorded with  25.0 fps!\n",
      "Overall # of frames:  3418 with cropped frame dimensions:  550 260\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3418/3418 [00:08<00:00, 397.85it/s]\n",
      "  1%|▏         | 38/2616 [00:00<00:06, 374.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /data/LiftFly3D/prism/side_view/videos ['/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly1_004_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_001_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_002_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_003_prism.mp4', '/data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4']\n",
      "Loading  /data/LiftFly3D/prism/side_view/videos/video_191125_PR_Fly2_004_prism.mp4 and data.\n",
      "2616\n",
      "Duration of video [s]:  104.64 , recorded with  25.0 fps!\n",
      "Overall # of frames:  2616 with cropped frame dimensions:  550 260\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2616/2616 [00:05<00:00, 442.45it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video(config_path,videofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
