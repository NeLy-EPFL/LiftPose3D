{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "from imp import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from load import load_data\n",
    "tqdm.get_lock().locks = []\n",
    "reload(logging)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare data parameters\n",
    "# out 00 -> without bln, 0.004\n",
    "par_train = {'data_dir'         : '/data/LiftPose3D/capture', # change the path\n",
    "            #'data_dir'       : r'\\Users\\NeLy\\Desktop\\capture', #windows path format\n",
    "             'out_dir'          : '/data/LiftPose3D/capture/out_across_animals_bone_normalized',\n",
    "             'train_session_id' : [1,2,3],\n",
    "             'test_session_id'  : [0],\n",
    "             'test_cam_id'      : [0]}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "train_3d, train_2d, train_keypoints, test_3d, test_2d, test_keypoints, cams, train_fid, test_fid, train_2d_sh, test_2d_sh  = load_data(par_train, return_frame_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess.py:416]:INFO:Bootstrapping mean and variance...\n",
      "[preprocess.py:420]:INFO:Loaded existing data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gosztolai/Dropbox/github/LiftPose3D/liftpose/preprocess.py:153: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tmp /= np.linalg.norm(tmp, ord='fro', axis=(1,2), keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main.py:190]:INFO:Saving pre-processed 2D data at /data/LiftPose3D/capture/out_across_animals_bone_normalized/stat_2d.pth.tar.\n",
      "[main.py:209]:INFO:Saving pre-processed 3D data at /data/LiftPose3D/capture/out_across_animals_bone_normalized/stat_3d.pth.tar.\n",
      "[main.py:237]:INFO:Starting training model.\n",
      "[main.py:248]:DEBUG:\n",
      "==================Options=================\n",
      "[main.py:249]:DEBUG:{   'batch_size': 64,\n",
      "    'data_dir': '/data/LiftPose3D/capture/out_across_animals_bone_normalized',\n",
      "    'drop_input': 0.0,\n",
      "    'dropout': 0.5,\n",
      "    'epochs': 20,\n",
      "    'exp': '',\n",
      "    'is_train': True,\n",
      "    'job': 8,\n",
      "    'linear_size': 1024,\n",
      "    'load': None,\n",
      "    'lr': 0.001,\n",
      "    'lr_decay': 5000,\n",
      "    'lr_gamma': 0.9,\n",
      "    'max_norm': True,\n",
      "    'noise': None,\n",
      "    'num_stage': 2,\n",
      "    'out': '/data/LiftPose3D/capture/out_across_animals_bone_normalized',\n",
      "    'out_dir': '/data/LiftPose3D/capture/out_across_animals_bone_normalized',\n",
      "    'predict': False,\n",
      "    'procrustes': False,\n",
      "    'resume': False,\n",
      "    'test': False}\n",
      "[main.py:250]:DEBUG:==========================================\n",
      "\n",
      "[lift.py:44]:INFO:Training on the device: cuda:0\n",
      "[lift.py:71]:INFO:total params: 4.31M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 000 | LR  0.00081 | Loss Test  0.00000 | Loss Train  0.25563|: 100%|██████████| 14826/14826 [02:18<00:00, 106.82it/s]\n",
      "Epoch 001 | LR  0.00059 | Loss Test  0.19984 | Loss Train  0.20981|: 100%|██████████| 14826/14826 [02:20<00:00, 105.48it/s]\n",
      "Epoch 002 | LR  0.00053 | Loss Test  0.19385 | Loss Train  0.20435|:  18%|█▊        | 2620/14826 [00:25<02:00, 100.90it/s]"
     ]
    }
   ],
   "source": [
    "from liftpose.main import train as lp3d_train\n",
    "from liftpose.lifter.augmentation import random_project, perturb_pose, project_to_cam\n",
    "from liftpose.vision_3d import intrinsic_matrix, calculate_bone_length\n",
    "from liftpose.preprocess import obtain_projected_stats\n",
    "\n",
    "\n",
    "# we assume camera-to-object distance and intrinsic matrix are unknown\n",
    "angle_aug = {'eangles': {0: [[-10,10], [-10, 10], [-10,10]]},\n",
    "            'axsorder': 'zyx',\n",
    "            'vis': None,\n",
    "            'tvec': None,\n",
    "            'intr': None}\n",
    "\n",
    "bone_len = calculate_bone_length(test_3d, par_data['vis']['bones'])\n",
    "avg_bone_len= np.nanmean(bone_len, axis=0)\n",
    "std_bone_len= np.nanstd(bone_len, axis=0)\n",
    "\n",
    "pose_aug = {'perturb': 1,\n",
    "            'child': par_data[\"vis\"][\"child\"],\n",
    "            'bones': par_data['vis']['bones'],\n",
    "            'avg_bone_len': avg_bone_len,\n",
    "            'std_bone_len': std_bone_len}\n",
    "\n",
    "\n",
    "stats = obtain_projected_stats({'train_3d':train_3d},\n",
    "                               angle_aug['eangles'], \n",
    "                               angle_aug['axsorder'], \n",
    "                               angle_aug['vis'],\n",
    "                               angle_aug['tvec'],\n",
    "                               angle_aug['intr'],\n",
    "                               par['roots'], \n",
    "                               par['target_sets'],\n",
    "                               par['out_dir'],\n",
    "                               load_existing=True,\n",
    "                               th=1)\n",
    "\n",
    "aug = [perturb_pose(**pose_aug), random_project(**angle_aug)]\n",
    "#aug = [random_project(**angle_aug)]\n",
    "\n",
    "lp3d_train(train_2d=None, test_2d={'test':test_2d},\n",
    "           train_3d={'train':train_3d}, test_3d={'test':test_3d},\n",
    "           train_keypts={'train':train_keypoints}, test_keypts={'test':test_keypoints}, \n",
    "           roots=par['roots'],\n",
    "           target_sets=par['target_sets'],\n",
    "           out_dir=par['out_dir'], \n",
    "           training_kwargs={\"epochs\":20},\n",
    "           augmentation=aug,\n",
    "           stats=stats,\n",
    "           norm_2d=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import read_log_train, plot_log_train\n",
    "epoch, lr, loss_train, loss_test = read_log_train(par['out_dir'])\n",
    "plot_log_train(plt.gca(), loss_train, loss_test, epoch)\n",
    "#plt.savefig('loss.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.main import test as lp3d_test\n",
    "lp3d_test(par['out_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.postprocess import load_test_results\n",
    "from liftpose.vision_3d import camera_to_world, pairwise_procrustes\n",
    "\n",
    "test_3d_gt, test_3d_pred, good_keypts = load_test_results(par['out_dir'])\n",
    "\n",
    "s = test_3d_gt.shape\n",
    "test_3d_gt = camera_to_world(test_3d_gt.reshape(s[0], -1), cams['R'][0], cams['tvec'][0]).reshape(s)\n",
    "test_3d_pred = camera_to_world(test_3d_pred.reshape(s[0],-1), cams['R'][0], cams['tvec'][0]).reshape(s)\n",
    "\n",
    "#change occluded points to nana\n",
    "ind_nan_pred = np.logical_not(test_keypoints)\n",
    "ind_nan_gt = np.logical_not(test_keypoints)\n",
    "ind_nan = (ind_nan_gt*ind_nan_pred).reshape(-1, 20, 3)\n",
    "test_3d_pred[ind_nan] = np.nan\n",
    "test_3d_gt[ind_nan] = np.nan\n",
    "\n",
    "#make nans to zeros for procrustes\n",
    "test_3d_pred[np.isnan(test_3d_pred)]=0\n",
    "test_3d_gt[np.isnan(test_3d_gt)]=0\n",
    "\n",
    "#remove all-0 poses\n",
    "ind_0_pred = (test_3d_pred.sum(2).sum(1)>0)\n",
    "ind_0_gt = (test_3d_gt.sum(2).sum(1)>0)\n",
    "ind_0 = ind_0_pred*ind_0_gt\n",
    "test_3d_pred = test_3d_pred[ind_0]\n",
    "test_3d_gt = test_3d_gt[ind_0]\n",
    "test_fid = test_fid[ind_0]\n",
    "test_2d_sh = test_2d_sh[ind_0]\n",
    "\n",
    "#procrustes align\n",
    "test_3d_pred = pairwise_procrustes(test_3d_gt, test_3d_pred)\n",
    "\n",
    "#put nans back\n",
    "test_3d_gt[ind_nan[ind_0]]=np.nan\n",
    "test_3d_pred[ind_nan[ind_0]]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "from liftpose.plot import plot_pose_3d\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "i=5\n",
    "plot_pose_3d(ax=ax, tar=test_3d_gt[i],\n",
    "             pred=test_3d_pred[i],\n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"], \n",
    "            normalize=False, show_pred_always=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from celluloid import Camera\n",
    "from liftpose.plot import plot_pose_2d, plot_pose_3d\n",
    "\n",
    "fig = plt.figure(figsize=(10,5), dpi=300)\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122)\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "plt.margins(0,0)\n",
    "\n",
    "cam_list = ['R', 'L', 'E', 'U', 'S', 'U2']\n",
    "camera = Camera(fig)\n",
    "for t in range(0, 5000):\n",
    "    frame_id = test_fid[t][0]\n",
    "    if os.path.isfile(f'/mnt/NAS/SG/CAPTURE/images/rat7M_e0/sample0_{frame_id}_Camera{cam_list[0]}.png'):\n",
    "    \n",
    "        plot_pose_3d(ax=ax, \n",
    "                     bones=par_data[\"vis\"][\"bones\"], \n",
    "                     pred=test_3d_pred[t], \n",
    "                     tar=test_3d_gt[t], \n",
    "                     limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "                     colors=par_data[\"vis\"][\"colors\"],\n",
    "                     normalize=False,\n",
    "                     legend=True)\n",
    "    \n",
    "        ax2.imshow(plt.imread(f'/mnt/NAS/SG/CAPTURE/images/rat7M_e0/sample0_{frame_id}_Camera{cam_list[0]}.png'))\n",
    "        \n",
    "        pt = test_2d_sh[t].reshape(-1,2)\n",
    "        plot_pose_2d(ax2, \n",
    "            pt, \n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            normalize=False\n",
    "        )\n",
    "        ax2.axis('off')\n",
    "        camera.snap()\n",
    "        \n",
    "camera.animate().save('prediction.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bone lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.vision_3d import calculate_bone_length\n",
    "bl_animal_1 = calculate_bone_length(train_3d, par_data['vis']['bones'])\n",
    "bl_animal_2 = calculate_bone_length(test_3d, par_data['vis']['bones'])\n",
    "plt.hist(bl_animal_1[:,1],label='animal 1',bins=100,density=True)\n",
    "plt.hist(bl_animal_2[:,1],label='animal 2',bins=100,density=True)\n",
    "plt.xlim([40,110])\n",
    "plt.ylabel('Spine length (mm)')\n",
    "#plt.savefig('spine_length.svg')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import violin_plot\n",
    "import random, string\n",
    "plt.figure(figsize=(10,5), dpi=100)\n",
    "names = ['HeadF','HeadB','HeadL','SpineF','SpineM','SpineL','Offset1','Offset2','HipL','HipR',\n",
    "         'ElbowL','ArmL','ShoulderL','ShoulderR','ElbowR','ArmR','KneeR','KneeL','ShinL','ShinR']\n",
    "\n",
    "violin_plot(plt.gca(), test_3d_gt=test_3d_gt, test_3d_pred=test_3d_pred, test_keypoints=np.ones_like(test_3d_gt),\n",
    "                joints_name=names, order=names, units='mm', body_length=260)\n",
    "#plt.savefig('errors_norm.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
