{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "from imp import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from load import load_data\n",
    "tqdm.get_lock().locks = []\n",
    "reload(logging)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare data parameters\n",
    "# out 00 -> without bln, 0.004\n",
    "par_train = {'data_dir'         : '/data/LiftPose3D/capture', # change the path \n",
    "             'out_dir'          : '/data/LiftPose3D/capture/out_across_animals',\n",
    "             'train_session_id' : [3],\n",
    "             'test_session_id'  : [0],\n",
    "             'test_cam_id'      : [0]}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "train_3d, train_2d, train_keypoints, test_3d, test_2d, test_keypoints, cams, train_fid, test_fid, train_2d_sh, test_2d_sh  = load_data(par_train, return_frame_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess.py:447]:INFO:Bootstrapping mean and variance...\n",
      "[preprocess.py:534]:INFO:Expected error for obtaining projection stats: 412.86111285717277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gosztolai/Dropbox/github/LiftPose3D/liftpose/preprocess.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tmp /= np.linalg.norm(tmp, ord='fro', axis=(1,2), keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess.py:534]:INFO:Expected error for obtaining projection stats: 0.11413355829789695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gosztolai/Dropbox/github/LiftPose3D/liftpose/preprocess.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tmp /= np.linalg.norm(tmp, ord='fro', axis=(1,2), keepdims=True)\n",
      "/home/gosztolai/Dropbox/github/LiftPose3D/liftpose/preprocess.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tmp /= np.linalg.norm(tmp, ord='fro', axis=(1,2), keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main.py:252]:INFO:Saving pre-processed 2D data at /data/LiftPose3D/capture/out_across_animals/stat_2d.pth.tar.\n",
      "[main.py:271]:INFO:Saving pre-processed 3D data at /data/LiftPose3D/capture/out_across_animals/stat_3d.pth.tar.\n",
      "[main.py:299]:INFO:Starting training model.\n",
      "[main.py:309]:DEBUG:\n",
      "==================Options=================\n",
      "[main.py:310]:DEBUG:{   'batch_size': 64,\n",
      "    'data_dir': '/data/LiftPose3D/capture/out_across_animals',\n",
      "    'drop_input': 0.0,\n",
      "    'dropout': 0.5,\n",
      "    'epochs': 30,\n",
      "    'exp': '',\n",
      "    'is_train': True,\n",
      "    'job': 8,\n",
      "    'linear_size': 1024,\n",
      "    'load': None,\n",
      "    'lr': 0.001,\n",
      "    'lr_decay': 5000,\n",
      "    'lr_gamma': 0.9,\n",
      "    'max_norm': True,\n",
      "    'noise': None,\n",
      "    'num_stage': 2,\n",
      "    'out': '/data/LiftPose3D/capture/out_across_animals',\n",
      "    'out_dir': '/data/LiftPose3D/capture/out_across_animals',\n",
      "    'predict': False,\n",
      "    'procrustes': False,\n",
      "    'resume': False,\n",
      "    'test': False}\n",
      "[main.py:311]:DEBUG:==========================================\n",
      "\n",
      "[lift.py:31]:INFO:Training on the device: cuda:0\n",
      "[lift.py:58]:INFO:total params: 4.31M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 000 | LR  0.00100 | Loss Test  0.00000 | Loss Train  0.65157|: 100%|██████████| 832/832 [00:06<00:00, 125.74it/s]\n",
      "Epoch 001 | LR  0.00100 | Loss Test  0.33139 | Loss Train  0.10289|: 100%|██████████| 832/832 [00:06<00:00, 131.82it/s]\n",
      "Epoch 002 | LR  0.00100 | Loss Test  0.23848 | Loss Train  0.08343|: 100%|██████████| 832/832 [00:06<00:00, 130.37it/s]\n",
      "Epoch 003 | LR  0.00100 | Loss Test  0.21595 | Loss Train  0.07680|: 100%|██████████| 832/832 [00:06<00:00, 129.41it/s]\n",
      "Epoch 004 | LR  0.00100 | Loss Test  0.19983 | Loss Train  0.07058|: 100%|██████████| 832/832 [00:06<00:00, 130.93it/s]\n",
      "Epoch 005 | LR  0.00100 | Loss Test  0.20059 | Loss Train  0.06717|: 100%|██████████| 832/832 [00:06<00:00, 129.52it/s]\n",
      "Epoch 006 | LR  0.00090 | Loss Test  0.21028 | Loss Train  0.06421|: 100%|██████████| 832/832 [00:06<00:00, 128.23it/s]\n",
      "Epoch 007 | LR  0.00090 | Loss Test  0.19494 | Loss Train  0.06200|: 100%|██████████| 832/832 [00:06<00:00, 132.12it/s]\n",
      "Epoch 008 | LR  0.00090 | Loss Test  0.18053 | Loss Train  0.05944|: 100%|██████████| 832/832 [00:06<00:00, 130.51it/s]\n",
      "Epoch 009 | LR  0.00090 | Loss Test  0.17385 | Loss Train  0.05857|: 100%|██████████| 832/832 [00:06<00:00, 129.82it/s]\n",
      "Exception in thread Thread-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/multiprocessing/queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/gosztolai/anaconda3/envs/LiftPose3D/lib/python3.8/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cda0e9bce24c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0maug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mangle_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m lp3d_train(train_2d=None, test_2d={'test':test_2d},\n\u001b[0m\u001b[1;32m     40\u001b[0m            \u001b[0mtrain_3d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_3d\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_3d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_3d\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m            \u001b[0mtrain_keypts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_keypoints\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_keypts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_keypoints\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/LiftPose3D/liftpose/main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_2d, test_2d, train_3d, test_3d, roots, target_sets, out_dir, train_keypts, test_keypts, training_kwargs, augmentation, stats, norm_2d)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==========================================\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mnetwork_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/LiftPose3D/liftpose/lifter/lift.py\u001b[0m in \u001b[0;36mnetwork_main\u001b[0;34m(opt, augmentation)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             loss_test, err_test, _, _, _, _, _, _ = test(\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat_3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             )\n",
      "\u001b[0;32m~/Dropbox/github/LiftPose3D/liftpose/lifter/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_loader, model, criterion, stat, predict)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mall_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mall_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mall_bool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_keypts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from liftpose.main import train as lp3d_train\n",
    "from liftpose.lifter.augmentation import random_project, perturb_pose, project_to_cam\n",
    "from liftpose.vision_3d import intrinsic_matrix, calculate_bone_length\n",
    "from liftpose.preprocess import obtain_projected_stats\n",
    "\n",
    "\n",
    "angle_aug = {'eangles': {0: [[-5,5], [-5, 5], [-5,5]]},\n",
    "            'axsorder': 'zyx',\n",
    "            'vis': None,\n",
    "            'tvec': None,\n",
    "            'intr': None}\n",
    "\n",
    "bone_len = calculate_bone_length(test_3d, par_data['vis']['bones'])\n",
    "avg_bone_len= np.nanmean(bone_len, axis=0)\n",
    "std_bone_len= np.nanstd(bone_len, axis=0)\n",
    "\n",
    "pose_aug = {'perturb': 2,\n",
    "            'child': par_data[\"vis\"][\"child\"],\n",
    "            'bones': par_data['vis']['bones'],\n",
    "            'avg_bone_len': avg_bone_len,\n",
    "            'std_bone_len': std_bone_len}\n",
    "\n",
    "\n",
    "stats = obtain_projected_stats({'train_3d':train_3d},\n",
    "                               angle_aug['eangles'], \n",
    "                               angle_aug['axsorder'], \n",
    "                               angle_aug['vis'],\n",
    "                               angle_aug['tvec'],\n",
    "                               angle_aug['intr'],\n",
    "                               par['roots'], \n",
    "                               par['target_sets'],\n",
    "                               par['out_dir'],\n",
    "                               load_existing=False,\n",
    "                               th=1)\n",
    "\n",
    "#aug = [perturb_pose(**pose_aug), random_project(**angle_aug)]\n",
    "aug = [random_project(**angle_aug)]\n",
    "\n",
    "lp3d_train(train_2d=None, test_2d={'test':test_2d},\n",
    "           train_3d={'train':train_3d}, test_3d={'test':test_3d},\n",
    "           train_keypts={'train':train_keypoints}, test_keypts={'test':test_keypoints}, \n",
    "           roots=par['roots'],\n",
    "           target_sets=par['target_sets'],\n",
    "           out_dir=par['out_dir'], \n",
    "           training_kwargs={\"epochs\":30},\n",
    "                            #\"resume\":True,\n",
    "                            #\"load\":par['out_dir'] + '/ckpt_last.pth.tar'},\n",
    "           augmentation=aug,\n",
    "           stats=stats,\n",
    "           norm_2d=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import read_log_train, plot_log_train\n",
    "epoch, lr, loss_train, loss_test, err_test = read_log_train(par['out_dir'])\n",
    "plot_log_train(plt.gca(), loss_train, loss_test, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.main import test as lp3d_test\n",
    "lp3d_test(par['out_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.postprocess import load_test_results\n",
    "from liftpose.vision_3d import camera_to_world, procrustes\n",
    "\n",
    "data = torch.load(os.path.join(par['out_dir'], \"test_results.pth.tar\"))\n",
    "stat_2d, stat_3d = (\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_2d.pth.tar\")),\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_3d.pth.tar\")),\n",
    ")\n",
    "\n",
    "test_3d_gt, test_3d_pred, good_keypts = load_test_results(data, stat_2d, stat_3d)\n",
    "\n",
    "s = test_3d_gt.shape\n",
    "test_3d_gt = camera_to_world(test_3d_gt.reshape(s[0], -1), cams['R'][0], cams['tvec'][0]).reshape(s)\n",
    "test_3d_pred = camera_to_world(test_3d_pred.reshape(s[0],-1), cams['R'][0], cams['tvec'][0]).reshape(s)\n",
    "\n",
    "#change occluded points to nana\n",
    "ind_nan_pred = np.logical_not(test_keypoints)\n",
    "ind_nan_gt = np.logical_not(test_keypoints)\n",
    "ind_nan = (ind_nan_gt*ind_nan_pred).reshape(-1, 20, 3)\n",
    "test_3d_pred[ind_nan] = np.nan\n",
    "test_3d_gt[ind_nan] = np.nan\n",
    "\n",
    "#make nans to zeros for procrustes\n",
    "test_3d_pred[np.isnan(test_3d_pred)]=0\n",
    "test_3d_gt[np.isnan(test_3d_gt)]=0\n",
    "\n",
    "#remove all-0 poses\n",
    "ind_0_pred = (test_3d_pred.sum(2).sum(1)>0)\n",
    "ind_0_gt = (test_3d_gt.sum(2).sum(1)>0)\n",
    "ind_0 = ind_0_pred*ind_0_gt\n",
    "test_3d_pred = test_3d_pred[ind_0]\n",
    "test_3d_gt = test_3d_gt[ind_0]\n",
    "test_fid = test_fid[ind_0]\n",
    "test_2d_sh = test_2d_sh[ind_0]\n",
    "\n",
    "#procrustes align\n",
    "test_3d_pred = procrustes(test_3d_gt, test_3d_pred)\n",
    "\n",
    "#put nans back\n",
    "test_3d_gt[ind_nan[ind_0]]=np.nan\n",
    "test_3d_pred[ind_nan[ind_0]]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "from liftpose.plot import plot_pose_3d\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "i=5\n",
    "plot_pose_3d(ax=ax, tar=test_3d_gt[i],\n",
    "             pred=test_3d_pred[i],\n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"], \n",
    "            normalize=False, show_pred_always=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from celluloid import Camera\n",
    "from liftpose.plot import plot_pose_2d, plot_pose_3d\n",
    "\n",
    "fig = plt.figure(figsize=(10,5), dpi=300)\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "cam_list = ['R', 'L', 'E', 'U', 'S', 'U2']\n",
    "camera = Camera(fig)\n",
    "for t in range(0, 10):\n",
    "    frame_id = test_fid[t][0]\n",
    "    if os.path.isfile(f'/mnt/NAS/SG/CAPTURE/images/rat7M_e0/sample0_{frame_id}_Camera{cam_list[0]}.png'):\n",
    "    \n",
    "        plot_pose_3d(ax=ax, tar=test_3d_gt[t], \n",
    "            pred=test_3d_pred[t], \n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            normalize=False,\n",
    "            legend=True)\n",
    "    \n",
    "        ax2.imshow(plt.imread(f'/mnt/NAS/SG/CAPTURE/images/rat7M_e0/sample0_{frame_id}_Camera{cam_list[0]}.png'))\n",
    "        \n",
    "        pt = test_2d_sh[t].reshape(-1,2)\n",
    "        plot_pose_2d(ax2, \n",
    "            pt, \n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            normalize=False\n",
    "        )\n",
    "        ax2.axis('off')\n",
    "        camera.snap()\n",
    "        \n",
    "camera.animate().save('prediction.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bone lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.vision_3d import calculate_bone_length\n",
    "bl_animal_1 = calculate_bone_length(train_3d, par_data['vis']['bones'])\n",
    "bl_animal_2 = calculate_bone_length(test_3d, par_data['vis']['bones'])\n",
    "plt.plot(bl_animal_1[:,3],label='animal 1')\n",
    "plt.plot(bl_animal_2[:,3],label='animal 2')\n",
    "plt.xlim([0,5000])\n",
    "#plt.ylim([40,120])\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Bone length (mm)')\n",
    "#plt.savefig('neck_length.svg')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import violin_plot\n",
    "import random, string\n",
    "plt.figure(figsize=(10,5), dpi=100)\n",
    "names = ['HeadF','HeadB','HeadL','SpineF','SpineM','SpineL','Offset1','Offset2','HipL','HipR',\n",
    "         'ElbowL','ArmL','ShoulderL','ShoulderR','ElbowR','ArmR','KneeR','KneeL','ShinL','ShinR']\n",
    "ax = plt.gca()\n",
    "violin_plot(ax, test_3d_gt=test_3d_gt, test_3d_pred=test_3d_pred, test_keypoints=np.ones_like(test_3d_gt),\n",
    "                joints_name=names, order=names)\n",
    "plt.savefig('errors_norm.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
