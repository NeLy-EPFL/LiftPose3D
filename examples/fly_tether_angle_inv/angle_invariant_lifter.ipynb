{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DeepFly3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load import *\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "from imp import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from liftpose.vision_3d import world_to_camera_dict, reprojection_error, intrinsic_matrix\n",
    "reload(logging)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.INFO)\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "# decleare data parameters\n",
    "par_train = {  'data_dir'       : '/data/LiftPose3D/fly_tether/data_DF3D', # change the path \n",
    "               'out_dir'        : '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
    "               'train_subjects' : [1],#,2,3,4,5,6,7],\n",
    "               'test_subjects'  : [6,7],\n",
    "               'actions'        : ['all'],\n",
    "               'cam_id'         : [0,6]}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "intr = None#intrinsic_matrix(171.0 * 94.0, 171.0 * 94.0, 240, 480) #intr = {0: intr,1: intr}\n",
    "tvec = None#{0: np.array([0, 0, 117]), 1: np.array([0, 0, 117])}\n",
    "\n",
    "#narrow\n",
    "training_kwargs = {'eangles': {0: [[-30,-20], [-2, 2], [-2,2]], 1: [[-270,-250], [-2, 2], [-2,2]]},\n",
    "                   'axsorder': 'yxz',\n",
    "                   'vis': {0: [1 if i<15 else 0 for i in range(30)], 1: [0 if i<15 else 1 for i in range(30)]},\n",
    "                   'tvec': tvec,\n",
    "                   'intr': intr}\n",
    "#wide\n",
    "#training_kwargs = {'eangles': {0: [[-90,-10], [-10, 10], [-2,2]], 1: [[-270,-180], [-10, 10], [-2,2]]},\n",
    "#                   'axsorder': 'yxz', \n",
    "#                   'intr': intr}\n",
    "\n",
    "# Load 2D data\n",
    "test_2d = load_2D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"test_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "\n",
    "# Load 3D data\n",
    "train_3d, train_keypts, rcams_train = load_3D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"train_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "test_3d, test_keypts, rcams_test = load_3D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"test_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LiftPose3D Network on DeepFly3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess.py:442]:INFO:Bootstrapping mean and variance...\n",
      "[preprocess.py:446]:INFO:Loaded existing data.\n"
     ]
    }
   ],
   "source": [
    "from liftpose.preprocess import obtain_projected_stats\n",
    "\n",
    "stats = obtain_projected_stats(train_3d,\n",
    "                               training_kwargs['eangles'], \n",
    "                               training_kwargs['axsorder'], \n",
    "                               training_kwargs['vis'],\n",
    "                               training_kwargs['tvec'],\n",
    "                               training_kwargs['intr'],\n",
    "                               par['roots'], \n",
    "                               par['target_sets'],\n",
    "                               par['out_dir'],\n",
    "                               load_existing=True,\n",
    "                               th=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main.py:250]:INFO:Saving pre-processed 2D data at /data/LiftPose3D/fly_tether/angle_inv_network/stat_2d.pth.tar.\n",
      "[main.py:269]:INFO:Saving pre-processed 3D data at /data/LiftPose3D/fly_tether/angle_inv_network/stat_3d.pth.tar.\n",
      "[main.py:297]:INFO:Starting training model.\n",
      "[main.py:307]:DEBUG:\n",
      "==================Options=================\n",
      "[main.py:308]:DEBUG:{   'batch_size': 64,\n",
      "    'data_dir': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'dropout': 0.5,\n",
      "    'epochs': 10,\n",
      "    'exp': '',\n",
      "    'is_train': True,\n",
      "    'job': 8,\n",
      "    'linear_size': 1024,\n",
      "    'load': None,\n",
      "    'lr': 0.001,\n",
      "    'lr_decay': 5000,\n",
      "    'lr_gamma': 0.9,\n",
      "    'max_norm': True,\n",
      "    'noise': None,\n",
      "    'num_stage': 2,\n",
      "    'out': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'out_dir': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'predict': False,\n",
      "    'procrustes': False,\n",
      "    'resume': False,\n",
      "    'test': False}\n",
      "[main.py:309]:DEBUG:==========================================\n",
      "\n",
      "[lift.py:31]:INFO:Training on the device: cuda:0\n",
      "[lift.py:53]:INFO:total params: 4.33M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 000 | LR  0.00100 | Loss Test  0.00000 | Loss Train  0.26100|: 100%|██████████| 3291/3291 [00:25<00:00, 129.59it/s]\n",
      "Epoch 001 | LR  0.00100 | Loss Test  0.06318 | Loss Train  0.15163|:  11%|█         | 368/3291 [00:03<00:25, 115.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9bd96b124ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtraining_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m lp3d_train(train_2d=None, test_2d=test_2d,\n\u001b[0m\u001b[1;32m      7\u001b[0m            \u001b[0mtrain_3d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_3d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_3d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m            \u001b[0mtrain_keypts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_keypts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/LiftPose3D/liftpose/main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_2d, test_2d, train_3d, test_3d, roots, target_sets, out_dir, train_keypts, test_keypts, training_kwargs, augmentation, stats)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==========================================\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mnetwork_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/LiftPose3D/liftpose/lifter/lift.py\u001b[0m in \u001b[0;36mnetwork_main\u001b[0;34m(opt, augmentation)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             glob_step, lr_now, loss_train = train(\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/LiftPose3D/liftpose/lifter/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, loss_test, lr_init, lr_now, glob_step, lr_decay, gamma, max_norm)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LiftPose3D/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/LiftPose3D/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from liftpose.main import train as lp3d_train\n",
    "from liftpose.lifter.augmentation import random_project\n",
    "\n",
    "aug = random_project(**training_kwargs)\n",
    "\n",
    "lp3d_train(train_2d=None, test_2d=test_2d,\n",
    "           train_3d=train_3d, test_3d=test_3d, \n",
    "           train_keypts=train_keypts,\n",
    "           test_keypts=test_keypts,\n",
    "           roots=par['roots'],\n",
    "           target_sets=par['target_sets'],\n",
    "           out_dir=par['out_dir'],\n",
    "           training_kwargs={\"epochs\":10},\n",
    "           augmentation=[aug],\n",
    "           stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import read_log_train, plot_log_train\n",
    "epoch, lr, loss_train, loss_test, err_test = read_log_train(par['out_dir'])\n",
    "plot_log_train(plt.gca(), loss_train, loss_test, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Trained LiftPose3D Network on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.main import test as lp3d_test\n",
    "lp3d_test(par['out_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.postprocess import load_test_results\n",
    "data = torch.load(os.path.join(par['out_dir'], \"test_results.pth.tar\"))\n",
    "stat_2d, stat_3d = (\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_2d.pth.tar\")),\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_3d.pth.tar\")),\n",
    ")\n",
    "test_3d_gt, test_3d_pred, good_keypts = load_test_results(data, stat_2d, stat_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/38865534/7554774\n",
    "# conda install ipympl\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "from liftpose.plot import plot_pose_3d\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(elev=90, azim=0)\n",
    "\n",
    "t = 10\n",
    "plot_pose_3d(ax=ax, tar=test_3d_gt[t], \n",
    "            pred=test_3d_pred[t], \n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            good_keypts=good_keypts[t],\n",
    "            show_gt_always=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
