{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DeepFly3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load import *\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "from imp import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from liftpose.vision_3d import world_to_camera_dict, reprojection_error, intrinsic_matrix\n",
    "reload(logging)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.INFO)\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "# decleare data parameters\n",
    "par_train = {  'data_dir'       : '/data/LiftPose3D/fly_tether/data_DF3D', # change the path \n",
    "               'out_dir'        : '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
    "               'train_subjects' : [1],\n",
    "               'test_subjects'  : [6,7],\n",
    "               'actions'        : ['all'],\n",
    "               'cam_id'         : [0,6]}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# Load 2D data\n",
    "train_2d = load_2D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"train_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "test_2d = load_2D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"test_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "\n",
    "# Load 3D data\n",
    "train_3d, train_keypts, rcams_train = load_3D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"train_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "test_3d, test_keypts, rcams_test = load_3D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"test_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "\n",
    "test_3d = world_to_camera_dict(test_3d, rcams_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LiftPose3D Network on DeepFly3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 1457.3895170879246\n",
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 15.415593097536046\n",
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 9.926375088710847\n",
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 17.15570434688674\n",
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 6.5767270201804875\n",
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 3.979429595523893\n",
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 1.8888398217881415\n",
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 4.374027288673904\n",
      "[preprocess.py:440]:INFO:Expected error for obtaining projection stats: 3.760816745498263\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e4ff78ef2f57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0maug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtraining_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0md_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_visible_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_keypts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m stats = obtain_projected_stats(d_train, \n\u001b[0m\u001b[1;32m     18\u001b[0m                               \u001b[0mtraining_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eangles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               \u001b[0mtraining_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axsorder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/fly_data_analysis/LiftPose3D/liftpose/preprocess.py\u001b[0m in \u001b[0;36mobtain_projected_stats\u001b[0;34m(poses, eangle, axsorder, intr, roots, target_sets, out_dir, th)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mintr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         )\n\u001b[0;32m--> 400\u001b[0;31m         pts_3d = process_dict(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mproject_to_random_eangle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mposes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/fly_data_analysis/LiftPose3D/liftpose/vision_3d.py\u001b[0m in \u001b[0;36mprocess_dict\u001b[0;34m(function, d, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0md_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# sort dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/fly_data_analysis/LiftPose3D/liftpose/vision_3d.py\u001b[0m in \u001b[0;36mproject_to_random_eangle\u001b[0;34m(poses_world, eangle_range, axsorder, project, intr)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0meangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mPcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_to_eangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes_world\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxsorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPcam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/fly_data_analysis/LiftPose3D/liftpose/vision_3d.py\u001b[0m in \u001b[0;36mproject_to_eangle\u001b[0;34m(poses_world, eangle, axsorder, project, intr)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;31m# obtain 3d pose in camera coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;31m# TODO remove the hard-coded value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0mPcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworld_to_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes_world\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m117\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# project to camera axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/github/fly_data_analysis/LiftPose3D/liftpose/vision_3d.py\u001b[0m in \u001b[0;36mworld_to_camera\u001b[0;34m(poses_world, R, tvec)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mposes_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes_world\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mposes_cam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes_world\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mposes_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes_world\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from liftpose.main import train as lp3d_train\n",
    "from liftpose.lifter.augmentation import random_project\n",
    "from liftpose.preprocess import obtain_projected_stats,  get_visible_points\n",
    "\n",
    "intr = intrinsic_matrix(171.0 * 94.0, 171.0 * 94.0, 240, 480)\n",
    "#narrow\n",
    "training_kwargs = {'eangles': {0: [[-30,-20], [-2, 2], [-2,2]], 1: [[-270,-250], [-2, 2], [-2,2]]},\n",
    "                   'axsorder': 'yxz', \n",
    "                   'intr': intr}\n",
    "#wide\n",
    "#training_kwargs = {'eangles': {0: [[-90,-10], [-10, 10], [-2,2]], 1: [[-270,-180], [-10, 10], [-2,2]]},\n",
    "#                   'axsorder': 'yxz', \n",
    "#                   'intr': intr}\n",
    "\n",
    "aug = random_project(**training_kwargs)\n",
    "d_train = get_visible_points(train_3d, train_keypts)\n",
    "stats = obtain_projected_stats(d_train, \n",
    "                              training_kwargs['eangles'], \n",
    "                              training_kwargs['axsorder'], \n",
    "                              training_kwargs['intr'], \n",
    "                              par['roots'], \n",
    "                              par['target_sets'],\n",
    "                              par['out_dir'], \n",
    "                              th=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pickle.load(open('/data/LiftPose3D/fly_tether/angle_inv_network/stats.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main.py:240]:INFO:Saving pre-processed 2D data at /data/LiftPose3D/fly_tether/angle_inv_network/stat_2d.pth.tar.\n",
      "[main.py:259]:INFO:Saving pre-processed 3D data at /data/LiftPose3D/fly_tether/angle_inv_network/stat_3d.pth.tar.\n",
      "[main.py:287]:INFO:Starting training model.\n",
      "[main.py:297]:DEBUG:\n",
      "==================Options=================\n",
      "[main.py:298]:DEBUG:{   'batch_size': 64,\n",
      "    'data_dir': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'dropout': 0.5,\n",
      "    'epochs': 30,\n",
      "    'exp': '',\n",
      "    'is_train': True,\n",
      "    'job': 8,\n",
      "    'linear_size': 1024,\n",
      "    'load': None,\n",
      "    'lr': 0.001,\n",
      "    'lr_decay': 5000,\n",
      "    'lr_gamma': 0.9,\n",
      "    'max_norm': True,\n",
      "    'noise': None,\n",
      "    'num_stage': 2,\n",
      "    'out': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'out_dir': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'predict': False,\n",
      "    'procrustes': False,\n",
      "    'resume': False,\n",
      "    'test': False}\n",
      "[main.py:299]:DEBUG:==========================================\n",
      "\n",
      "[lift.py:31]:INFO:Training on the device: cuda:0\n",
      "[lift.py:53]:INFO:total params: 4.33M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 000 | LR  0.00100 | Loss Test  0.00000 | Loss Train  0.00000|:   0%|          | 0/3291 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -1.5429, -0.6528, -5.3006, -1.3123,\n",
      "        -0.8970, -2.1795, -0.7023,  4.0008,  1.1199,  2.0887,  9.0526, -1.6259,\n",
      "        -2.7258,  1.7153,  2.3560, -0.5842, -5.7141,  1.9024,  7.0294,  0.1747,\n",
      "        -0.2390, -3.3905,  8.2684,  9.2919, -2.3028,  1.5776,  0.1127, -1.8239,\n",
      "        -0.9101,  6.8911, -7.1719,  4.1074, -2.2328,  1.9417, -3.3321,  7.7410],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "           0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
      "          -0.7870,   17.3087,   34.4835,   21.2679,   92.3974,   56.6757,\n",
      "          11.8704,   60.5546,   51.7353,    6.7456,   42.3431,   43.6158,\n",
      "           6.2740,  -53.1600,    5.4615,   -3.1061,  160.2160,   83.5013,\n",
      "          -1.4435,  155.7929,   58.6960,    4.8424,  101.8179,   39.0356,\n",
      "          51.2787, -130.9948,   90.2616,   40.3131,  119.6549,   96.4362,\n",
      "          33.4295,  128.4837,   55.7405,   32.9641,   93.3614,   28.9383],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lp3d_train(train_2d=train_2d, test_2d=test_2d,\n",
    "           train_3d=train_3d, test_3d=test_3d, \n",
    "           train_keypts=train_keypts,\n",
    "           test_keypts=test_keypts,\n",
    "           roots=par['roots'],\n",
    "           target_sets=par['target_sets'],\n",
    "           out_dir=par['out_dir'],\n",
    "           augmentation=[aug],\n",
    "           mean=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import read_log_train, plot_log_train\n",
    "epoch, lr, loss_train, loss_test, err_test = read_log_train(par['out_dir'])\n",
    "plot_log_train(plt.gca(), loss_train, loss_test, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Trained LiftPose3D Network on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.main import test as lp3d_test\n",
    "lp3d_test(par['out_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.postprocess import load_test_results\n",
    "data = torch.load(os.path.join(par['out_dir'], \"test_results.pth.tar\"))\n",
    "stat_2d, stat_3d = (\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_2d.pth.tar\")),\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_3d.pth.tar\")),\n",
    ")\n",
    "test_3d_gt, test_3d_pred, good_keypts = load_test_results(data, stat_2d, stat_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/38865534/7554774\n",
    "# conda install ipympl\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "from liftpose.plot import plot_pose_3d\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(elev=90, azim=0)\n",
    "\n",
    "t = 0\n",
    "plot_pose_3d(ax=ax, tar=test_3d_gt[t], \n",
    "            pred=test_3d_pred[t], \n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            good_keypts=good_keypts[t],\n",
    "            show_gt_always=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
