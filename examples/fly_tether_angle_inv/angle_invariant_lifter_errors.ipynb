{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DeepFly3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load import *\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "from imp import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from liftpose.preprocess import process_dict\n",
    "from liftpose.vision_3d import world_to_camera_dict, reprojection_error, intrinsic_matrix, project_to_random_eangle\n",
    "reload(logging)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.INFO)\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "# decleare data parameters\n",
    "par_train = {  'data_dir'       : '/data/LiftPose3D/fly_tether/data_DF3D', # change the path \n",
    "               'out_dir'        : '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
    "               'train_subjects' : [1,2,3,4,5,6,7],\n",
    "               'test_subjects'  : [6,7],\n",
    "               'actions'        : ['all'],\n",
    "               'cam_id'         : [0]}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# Load 3D data\n",
    "train_3d, train_keypts, rcams_train = load_3D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"train_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "\n",
    "test_3d, test_keypts, rcams_test = load_3D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"test_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "\n",
    "\n",
    "#obtain 2D data by projection\n",
    "intr = intrinsic_matrix(171.0 * 94.0, 171.0 * 94.0, 240, 480)\n",
    "training_kwargs = {'eangles': {0: [[-30,-20], [-2, 2], [-2,2]]},\n",
    "                   'axsorder': 'yxz', \n",
    "                   'intr': intr}\n",
    "\n",
    "test_2d = process_dict(\n",
    "            project_to_random_eangle,\n",
    "            test_3d,\n",
    "            training_kwargs['eangles'],\n",
    "            axsorder=training_kwargs['axsorder'],\n",
    "            project=True,\n",
    "            intr=training_kwargs['intr'],\n",
    "        )\n",
    "\n",
    "test_2d = load_2D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"test_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LiftPose3D Network on DeepFly3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.preprocess import obtain_projected_stats, get_visible_points\n",
    "\n",
    "#wide\n",
    "#training_kwargs = {'eangles': {0: [[-90,-10], [-10, 10], [-2,2]], 1: [[-270,-180], [-10, 10], [-2,2]]},\n",
    "#                   'axsorder': 'yxz', \n",
    "#                   'intr': intr}\n",
    "\n",
    "d_train = get_visible_points(train_3d, train_keypts)\n",
    "stats = obtain_projected_stats(d_train, \n",
    "                              training_kwargs['eangles'], \n",
    "                              training_kwargs['axsorder'], \n",
    "                              training_kwargs['intr'], \n",
    "                              par['roots'], \n",
    "                              par['target_sets'],\n",
    "                              par['out_dir'], \n",
    "                              th=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pickle.load(open('/data/LiftPose3D/fly_tether/angle_inv_network/stats.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main.py:250]:INFO:Saving pre-processed 2D data at /data/LiftPose3D/fly_tether/angle_inv_network/stat_2d.pth.tar.\n",
      "[main.py:269]:INFO:Saving pre-processed 3D data at /data/LiftPose3D/fly_tether/angle_inv_network/stat_3d.pth.tar.\n",
      "[main.py:297]:INFO:Starting training model.\n",
      "[main.py:307]:DEBUG:\n",
      "==================Options=================\n",
      "[main.py:308]:DEBUG:{   'batch_size': 64,\n",
      "    'data_dir': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'dropout': 0.5,\n",
      "    'epochs': 5,\n",
      "    'exp': '',\n",
      "    'is_train': True,\n",
      "    'job': 8,\n",
      "    'linear_size': 1024,\n",
      "    'load': None,\n",
      "    'lr': 0.001,\n",
      "    'lr_decay': 5000,\n",
      "    'lr_gamma': 0.9,\n",
      "    'max_norm': True,\n",
      "    'noise': None,\n",
      "    'num_stage': 2,\n",
      "    'out': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'out_dir': '/data/LiftPose3D/fly_tether/angle_inv_network',\n",
      "    'predict': False,\n",
      "    'procrustes': False,\n",
      "    'resume': False,\n",
      "    'test': False}\n",
      "[main.py:309]:DEBUG:==========================================\n",
      "\n",
      "[lift.py:31]:INFO:Training on the device: cuda:0\n",
      "[lift.py:53]:INFO:total params: 4.33M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5822 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan]][[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan]]"
     ]
    }
   ],
   "source": [
    "from liftpose.main import train as lp3d_train\n",
    "from liftpose.lifter.augmentation import random_project\n",
    "aug = random_project(**training_kwargs)\n",
    "\n",
    "lp3d_train(train_2d=None, test_2d=test_2d,\n",
    "           train_3d=train_3d, test_3d=test_3d, \n",
    "           train_keypts=train_keypts,\n",
    "           test_keypts=test_keypts,\n",
    "           roots=par['roots'],\n",
    "           target_sets=par['target_sets'],\n",
    "           out_dir=par['out_dir'],\n",
    "           training_kwargs={\"epochs\":5},\n",
    "           augmentation=[aug],\n",
    "           mean=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import read_log_train, plot_log_train\n",
    "epoch, lr, loss_train, loss_test, err_test = read_log_train(par['out_dir'])\n",
    "plot_log_train(plt.gca(), loss_train, loss_test, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Trained LiftPose3D Network on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.main import test as lp3d_test\n",
    "lp3d_test(par['out_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.postprocess import load_test_results\n",
    "data = torch.load(os.path.join(par['out_dir'], \"test_results.pth.tar\"))\n",
    "stat_2d, stat_3d = (\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_2d.pth.tar\")),\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_3d.pth.tar\")),\n",
    ")\n",
    "test_3d_gt, test_3d_pred, good_keypts = load_test_results(data, stat_2d, stat_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/38865534/7554774\n",
    "# conda install ipympl\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "from liftpose.plot import plot_pose_3d\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(elev=90, azim=0)\n",
    "\n",
    "t = 10\n",
    "plot_pose_3d(ax=ax, tar=test_3d_gt[t], \n",
    "            pred=test_3d_pred[t], \n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            good_keypts=good_keypts[t],\n",
    "            show_gt_always=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
