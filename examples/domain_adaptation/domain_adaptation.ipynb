{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import load_prism\n",
    "import load_tether\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from liftpose.vision_3d import *\n",
    "from liftpose.preprocess import concat_dict, total_frames, center_poses, anchor_to_root, flatten_dict, unflatten_dict\n",
    "from liftpose.plot import plot_pose_3d, plot_pose_2d\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in the source domain (tethered fly) and rotate it to ventral camera angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare data parameters\n",
    "par_train = {  'data_dir'       : '/data/LiftPose3D/fly_tether/data_DF3D', # change the path \n",
    "              #'data_dir'       : r'\\Users\\NeLy\\Desktop\\fly_tether', #windows path format\n",
    "               'out_dir'        : '/data/LiftPose3D/domain_adaptation',\n",
    "               'train_subjects' : [1,2,3,4,5],\n",
    "               'test_subjects'  : [6,7],\n",
    "               'actions'        : ['all']}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par_source = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# Load 3D data\n",
    "pts3d_source = load_tether.load_3D(\n",
    "    par_source[\"data_dir\"],\n",
    "    par_source,\n",
    "    subjects=par_source[\"train_subjects\"],\n",
    "    actions=par_source[\"actions\"],\n",
    ")\n",
    "\n",
    "#center\n",
    "pts3d_source = center_poses(pts3d_source)\n",
    "\n",
    "#concatenate dicts of experiments\n",
    "pts3d_source = concat_dict(pts3d_source)\n",
    "\n",
    "#roots are bit wobbly across frames so stabilize them by anchoring and then adding the root for frame #1\n",
    "#pts3d_source = flatten_dict(pts3d_source)\n",
    "#pts3d_source, offset = anchor_to_root(pts3d_source, par_source['roots'], par_source['target_sets'], 3)\n",
    "#k0 = None\n",
    "#for k in pts3d_source.keys():\n",
    "#    if k0 is None:\n",
    "#        k0=k\n",
    "#    pts3d_source[k] += offset[k0][0,:]\n",
    "\n",
    "#pts3d_source = unflatten_dict(pts3d_source,3)    \n",
    "#pts3d_source = pts3d_source['']\n",
    "\n",
    "#project to ventral view\n",
    "pts2d_source = project_to_eangle(pts3d_source, [-90,0,0], axsorder='xzy', project=True)\n",
    "#pts3d_source = project_to_eangle(pts3d_source, [-90,0,0], axsorder='xzy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in the target domain (fly in prism-mirror setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare data parameters\n",
    "par_train = {'data_dir'       : \"/data/LiftPose3D/fly_tether/data_DF3D_prism/\", # change the path\n",
    "             'out_dir'        : '/data/LiftPose3D/domain_adaptation',\n",
    "             \"train_subjects\" : ['Flyprism1','Flyprism2'],\n",
    "             'actions'        : ['PR']}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# load data\n",
    "pts3d_target, keypts_target, _ = load_prism.load_3D(par[\"data_dir\"], \n",
    "                                            subjects=par['train_subjects'], \n",
    "                                            actions=par['actions'])\n",
    "\n",
    "#concatenate dicts of experiments\n",
    "pts3d_target = concat_dict(pts3d_target)\n",
    "keypts_target = concat_dict(keypts_target)\n",
    "\n",
    "L = [i for i in range(15)]\n",
    "R = [i for i in range(15,30)]\n",
    "\n",
    "#select only high confidence points with roots\n",
    "ind = ((keypts_target[:,L,:].max(2).sum(1)==15) | (keypts_target[:,R,:].max(2).sum(1)==15)) & (keypts_target[:,par['roots'],:].max(2).sum(1)==3)\n",
    "pts3d_target = pts3d_target[ind]\n",
    "keypts_target = keypts_target[ind]\n",
    "\n",
    "#roots are bit wobbly across frames so stabilize them by anchoring and then adding the root for frame #1\n",
    "pts3d_target = flatten_dict(pts3d_target)\n",
    "pts3d_target, offset = anchor_to_root(pts3d_target, par['roots'], par['target_sets'], 3)\n",
    "k0 = None\n",
    "for k in pts3d_target.keys():\n",
    "    if k0 is None:\n",
    "        k0=k\n",
    "    pts3d_target[k] += offset[k0][0,:]\n",
    "    \n",
    "pts3d_target = unflatten_dict(pts3d_target,3)\n",
    "\n",
    "#project data to ventral view\n",
    "pts2d_target = XY_coord_dict(pts3d_target)\n",
    "\n",
    "pts2d_target = pts2d_target['']\n",
    "pts3d_target = pts3d_target['']\n",
    "\n",
    "#ind = [i for i in range(2000,6000)]\n",
    "ind = [i for i in range(0,500)]\n",
    "pts2d_target = pts2d_target[ind]\n",
    "pts3d_target = pts3d_target[ind]\n",
    "keypts_target = keypts_target[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test_pose = torch.load('test_2d_DF3D.pth.tar')\n",
    "test_pose = unflatten_dict(test_pose,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pose = concat_dict(test_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 10\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(121)\n",
    "plot_pose_2d(\n",
    "    ax, \n",
    "    test_pose[ind], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =0\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=50)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plot_pose_3d(ax=ax, tar=pts3d_target[idx],\n",
    "        #pred=pred,\n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "        colors=par_data[\"vis\"][\"colors\"],\n",
    "        good_keypts = keypts_target[idx],\n",
    "        normalize=False,\n",
    "        legend=True,\n",
    "        axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from liftpose.plot import plot_video_3d\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=50)\n",
    "ax = fig.add_subplot(111)#, projection='3d')\n",
    "#ax.view_init(elev=30, azim=140)\n",
    "\n",
    "def f(ax, idx):\n",
    "    ax.cla()\n",
    "\n",
    "    #plot_pose_3d(ax=ax, tar=pts3d_target[idx],\n",
    "    #    #pred=pred,\n",
    "    #    bones=par_data[\"vis\"][\"bones\"], \n",
    "    #    limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "    #    colors=par_data[\"vis\"][\"colors\"],\n",
    "    #    #good_keypts = keypts_target[idx],\n",
    "    #    normalize=False,\n",
    "    #    legend=True,\n",
    "    #    axes=True)\n",
    "    \n",
    "    plot_pose_2d(\n",
    "        ax, \n",
    "        test_pose[idx],#tar[idx,:,:2], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    colors=par_data[\"vis\"][\"colors\"], \n",
    "    )\n",
    "    #ax.set_xlim([-200,200])\n",
    "    #ax.set_ylim([-200,200])\n",
    "    #ax.set_zlim([-40,40])\n",
    "    \n",
    "plot_video_3d(fig, ax, n=250, fps=20, draw_function=f, name='LiftPose3D_prediction.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pose = pts3d_target[0, :, :].copy()\n",
    "kp = keypts_target.max(2).copy()\n",
    "pts = pts3d_source.copy()\n",
    "    \n",
    "for i in range(pts.shape[0]):\n",
    "    pts_tmp = pts[i,kp[i],:]\n",
    "    \n",
    "    target_tmp = target_pose[]\n",
    "            # pts[i,~kp] = 0\n",
    "            # target_pose[~kp] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5d37dfe57b4e499937cf410f0ea66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5082d5f04a3459580230a0ba994c74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.contrib.concurrent import process_map\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "nn = 20\n",
    "frac_samples = 0.1\n",
    "\n",
    "try:\n",
    "    poses, nns_2d, nns_3d = pickle.load(open(par_train['out_dir']+'/neighbors.pkl','rb'))\n",
    "\n",
    "except:   \n",
    "    total = pts3d_target.shape[0]\n",
    "    poses = [i for i in range(int(frac_samples*total))]\n",
    "    #poses = np.random.choice([i for i in range(total)], size=int(frac_samples*total), replace=False)\n",
    "\n",
    "    #3D poses\n",
    "    nns_3d = process_map(partial(find_neighbours, \n",
    "                         pts=pts3d_source, \n",
    "                         target_pts=pts3d_target, \n",
    "                         nn=nn),\n",
    "                         #good_keypts=keypts_target), \n",
    "                  poses, max_workers=16)\n",
    "                         \n",
    "    #2D poses\n",
    "    nns_2d = process_map(partial(find_neighbours, \n",
    "                         pts=pts2d_source,\n",
    "                         target_pts=pts2d_target, \n",
    "                         nn=nn), \n",
    "                  poses, max_workers=16)\n",
    "\n",
    "    pickle.dump([poses, nns_2d,nns_3d],open(par_train['out_dir']+'/neighbors.pkl','wb'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how much data is needed to generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "poses = np.array(poses)\n",
    "nns_2d = np.array(nns_2d)\n",
    "frac = np.linspace(0.1,1,10)\n",
    "error = []\n",
    "ind = range(len(poses))\n",
    "fold = 10\n",
    "for s in range(fold): #10-fold cross validation\n",
    "    ind_test = random.sample(ind,int(1/fold*len(ind)))\n",
    "    diff = set(ind) - set(ind_test)\n",
    "    \n",
    "    err = []\n",
    "    for f in frac:\n",
    "        ind_train = random.sample(diff,int(f*len(diff)))\n",
    "        A_est_2D = best_linear_map(pts2d_source,pts2d_target[poses[ind_train]],nns_2d[ind_train],nn=5)\n",
    "        pts2d_prism = apply_linear_map(A_est_2D, pts2d_target[poses[ind_test]])\n",
    "        err.append(np.abs(pts2d_source[nns_2d[ind_test][:,:1]] - pts2d_prism).mean())\n",
    "        \n",
    "    error.append(np.array(err))\n",
    "    \n",
    "error = np.array(error)\n",
    "plt.plot(frac*len(poses)*(1-1/fold), error.mean(0))\n",
    "plt.ylabel('Normalized distance to nearest neighbor (a.u.)')\n",
    "plt.xlabel('Number of poses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best linear transformation for 2D, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#A_est_2D = pickle.load(open('prism_to_DF3D_2D.pkl','rb'))\n",
    "\n",
    "nn=10\n",
    "\n",
    "A_est_2D = best_linear_map(pts2d_source, pts2d_target[poses], nns_2d, nn=nn)\n",
    "pts2d_prism = apply_linear_map(A_est_2D, pts2d_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 10\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(121)\n",
    "plot_pose_2d(\n",
    "    ax, \n",
    "    pts2d_target[poses[ind]], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    ")\n",
    "ax.set_title('Target domain pose')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.set_title('Source domain poses')\n",
    "\n",
    "for i in nns_2d[ind][:nn]:\n",
    "    plot_pose_2d(\n",
    "        ax, \n",
    "        pts2d_source[i], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "        colors=par_data[\"vis\"][\"colors\"], \n",
    "    )\n",
    "    \n",
    "plot_pose_2d(\n",
    "    ax, \n",
    "    pts2d_prism[poses[ind]], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    ")\n",
    "#plt.savefig('2D_mapping.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best linear transformation for 3D, d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 2\n",
    "\n",
    "#L = [i for i in range(15)]\n",
    "#R = [i for i in range(15,30)]\n",
    "\n",
    "#L_ind = (keypts_target[:,L,:].max(2).sum(1)>13)\n",
    "#R_ind = (keypts_target[:,R,:].max(2).sum(1)>13)\n",
    "\n",
    "#L_ind = np.where(L_ind[poses])[0]\n",
    "#R_ind = np.where(R_ind[poses])[0]\n",
    "\n",
    "#nns_L = [nns_3d[i] for i in L_ind]\n",
    "#nns_R = [nns_3d[i] for i in R_ind]\n",
    "\n",
    "#A_est_3D_L = best_linear_map(pts3d_source[:,L,:], pts3d_target[poses][L_ind][:,L,:], nns_L, nn=nn)\n",
    "#A_est_3D_R = best_linear_map(pts3d_source[:,R,:], pts3d_target[poses][R_ind][:,R,:], nns_R, nn=nn)\n",
    "\n",
    "#A_est_3D = np.block([[A_est_3D_L,                np.zeros_like(A_est_3D_L)],\n",
    "#                     [np.zeros_like(A_est_3D_R), A_est_3D_R ]])\n",
    "\n",
    "A_est_3D = best_linear_map(pts3d_source,pts3d_target[poses],nns_3d,nn=nn)\n",
    "pts3d_prism = apply_linear_map(A_est_3D, pts3d_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "nn=2\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax1 = fig.add_subplot(121, projection=\"3d\")\n",
    "ax2 = fig.add_subplot(122, projection=\"3d\")\n",
    "\n",
    "plot_pose_3d(ax=ax1, tar=pts3d_target[ind],\n",
    "        #pred=pred,\n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "        colors=par_data[\"vis\"][\"colors\"],\n",
    "        #good_keypts = keypts_target[ind],\n",
    "        normalize=False,\n",
    "        legend=True,\n",
    "        axes=True)\n",
    "\n",
    "for i in nns_3d[ind][:nn]:\n",
    "    plot_pose_3d(\n",
    "        ax2, \n",
    "        pts3d_source[i], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "        colors=par_data[\"vis\"][\"colors\"], \n",
    "        #good_keypts=keypts_target[poses[ind]]\n",
    "    )   \n",
    "    \n",
    "plot_pose_3d(\n",
    "    ax2, \n",
    "    pts3d_prism[poses[ind]], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    "    #good_keypts=keypts_target[poses[ind]]\n",
    ")\n",
    "    \n",
    "#plt.savefig('3D_mapping.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from liftpose.plot import plot_video_3d\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "def f(ax, ind):\n",
    "    \n",
    "    ax.cla()\n",
    "\n",
    "    plot_pose_3d(\n",
    "        ax, \n",
    "        pts3d_target[poses[ind]], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "        colors=par_data[\"vis\"][\"colors\"],\n",
    "        good_keypts=keypts_target[poses[ind]]\n",
    "    )\n",
    "    #ax.set_title('Source domain poses')\n",
    "\n",
    "    #for i in nns_3d[ind][:nn]:\n",
    "    #    plot_pose_3d(\n",
    "    #        ax, \n",
    "    #        pts3d_source[i], \n",
    "    #        bones=par_data[\"vis\"][\"bones\"], \n",
    "    #        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #        colors=par_data[\"vis\"][\"colors\"], \n",
    "    #        good_keypts=None\n",
    "    #    ) \n",
    "    \n",
    "plot_video_3d(fig, ax, n=250, fps=5, draw_function=f, name='LiftPose3D_prediction.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict poses with trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.postprocess import load_test_results\n",
    "from liftpose.main import set_test_data\n",
    "from liftpose.main import test as lp3d_test\n",
    "from liftpose.lifter.utils import filter_data\n",
    "\n",
    "kp = keypts_target\n",
    "        \n",
    "#normalize test data\n",
    "test_2d, test_3d, stat_2d, stat_3d = set_test_data(par['out_dir'], {'':pts2d_prism.copy()}, {'':pts3d_prism.copy()})\n",
    "    \n",
    "#test data on network\n",
    "lp3d_test(par['out_dir'],test_2d, test_3d)\n",
    "    \n",
    "#load statistics and test results\n",
    "gt, pred, _ = load_test_results(par['out_dir'], stat_2d, stat_3d)\n",
    "\n",
    "#filter noise\n",
    "#test_3d_gt = filter_data(test_3d_gt)\n",
    "#test_3d_pred = filter_data(test_3d_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import plot_pose_3d\n",
    "\n",
    "t = 0\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "plot_pose_3d(ax=ax, tar=gt[t], \n",
    "            pred=pred[t],\n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            good_keypts=kp[t],\n",
    "            show_pred_always=True,\n",
    "            legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.plot import plot_video_3d\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=300)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "def f(ax, idx):\n",
    "    ax.cla()\n",
    "\n",
    "    plot_pose_3d(ax=ax, tar=gt[idx], \n",
    "            pred=pred[idx],\n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            good_keypts=kp[idx],\n",
    "            show_pred_always=True,\n",
    "            legend=True)\n",
    "    \n",
    "    ax.set_xlim([-2,2])\n",
    "    ax.set_ylim([-2,2])\n",
    "    ax.set_zlim([-1.5,0.5])\n",
    "    \n",
    "plot_video_3d(fig, ax, n=50, fps=20, draw_function=f, name='LiftPose3D_prediction.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
