{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import load_prism\n",
    "import load_tether\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from liftpose.vision_3d import *\n",
    "from liftpose.preprocess import concat_dict, total_frames, center_poses, anchor_to_root, flatten_dict, unflatten_dict\n",
    "from liftpose.plot import plot_pose_3d, plot_pose_2d\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in the source domain (tethered fly) and rotate it to ventral camera angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare data parameters\n",
    "par_train = {  'data_dir'       : '/data/LiftPose3D/fly_tether/data_DF3D', # change the path \n",
    "              #'data_dir'       : r'\\Users\\NeLy\\Desktop\\fly_tether', #windows path format\n",
    "               'out_dir'        : '/data/LiftPose3D/domain_adaptation',\n",
    "               'train_subjects' : [1,2,3,4,5],\n",
    "               'test_subjects'  : [6,7],\n",
    "               'actions'        : ['all'],\n",
    "               'cam_id'         : [0]} #dummy camera\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par_source = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# Load 3D data\n",
    "pts3d_source, _, _ = load_tether.load_3D(\n",
    "    par_source[\"data_dir\"],\n",
    "    par_source,\n",
    "    cam_id=par_source[\"cam_id\"],\n",
    "    subjects=par_source[\"train_subjects\"],\n",
    "    actions=par_source[\"actions\"],\n",
    ")\n",
    "\n",
    "#concatenate dicts of experiments\n",
    "pts3d_source = concat_dict(pts3d_source)\n",
    "\n",
    "#roots are bit wobbly across frames so stabilize them by anchoring and then adding the root for frame #1\n",
    "pts3d_source = flatten_dict(pts3d_source)\n",
    "pts3d_source, offset = anchor_to_root(pts3d_source, par_source['roots'], par_source['target_sets'], 3)\n",
    "k0 = None\n",
    "for k in pts3d_source.keys():\n",
    "    if k0 is None:\n",
    "        k0=k\n",
    "    pts3d_source[k] += offset[k0][0,:]\n",
    "\n",
    "pts3d_source = unflatten_dict(pts3d_source,3)    \n",
    "pts3d_source = pts3d_source['']\n",
    "\n",
    "#project to ventral view\n",
    "pts2d_source = project_to_eangle(pts3d_source, [-90,0,0], axsorder='xzy', project=True)\n",
    "pts3d_source = project_to_eangle(pts3d_source, [-90,0,0], axsorder='xzy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in the target domain (fly in prism-mirror setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare data parameters\n",
    "par_train = {'data_dir'       : \"/data/LiftPose3D/fly_prism/data_oriented/test_data\", # change the path\n",
    "             'out_dir'        : '/data/LiftPose3D/domain_adaptation',\n",
    "             \"train_subjects\" : [\"001\", \"002\", \"003\",\"004\"],\n",
    "             'test_subjects'  : [\"004\"],\n",
    "             'actions'        : ['PR']}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# load data\n",
    "pts3d_target, keypts_target, _ = load_prism.load_3D(par[\"data_dir\"], \n",
    "                                            subjects=par['train_subjects'], \n",
    "                                            actions=par['actions'])\n",
    "\n",
    "#concatenate dicts of experiments\n",
    "pts3d_target = concat_dict(pts3d_target)\n",
    "keypts_target = concat_dict(keypts_target)\n",
    "\n",
    "#select only high confidence points with roots\n",
    "ind = (keypts_target.max(2).sum(1)>12) & (keypts_target[:,par['roots'],:].max(2).sum(1)==3)\n",
    "pts3d_target = pts3d_target[ind]\n",
    "keypts_target = keypts_target[ind]\n",
    "\n",
    "#roots are bit wobbly across frames so stabilize them by anchoring and then adding the root for frame #1\n",
    "pts3d_target = flatten_dict(pts3d_target)\n",
    "pts3d_target, offset = anchor_to_root(pts3d_target, par['roots'], par['target_sets'], 3)\n",
    "k0 = None\n",
    "for k in pts3d_target.keys():\n",
    "    if k0 is None:\n",
    "        k0=k\n",
    "    pts3d_target[k] += offset[k0][0,:]\n",
    "    \n",
    "pts3d_target = unflatten_dict(pts3d_target,3)\n",
    "\n",
    "#project data to ventral view\n",
    "pts2d_target = XY_coord_dict(pts3d_target)\n",
    "\n",
    "pts2d_target = pts2d_target['']\n",
    "pts3d_target = pts3d_target['']\n",
    "\n",
    "ind = [i for i in range(2000,6000)]\n",
    "pts2d_target = pts2d_target[ind]\n",
    "pts3d_target = pts3d_target[ind]\n",
    "keypts_target = keypts_target[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=50)\n",
    "ax = fig.add_subplot(111)#, projection='3d')\n",
    "\n",
    "ind=poses[0]\n",
    "\n",
    "plot_pose_2d(\n",
    "        ax, \n",
    "        pts2d_target[ind,:,:2], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ind = [i for i in range(2000,6000)]\n",
    "tar = pts3d_target[ind,:]\n",
    "#keypts = keypts_source[ind,:]\n",
    "\n",
    "from liftpose.plot import plot_video_3d\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=50)\n",
    "ax = fig.add_subplot(111)#, projection='3d')\n",
    "#ax.view_init(elev=30, azim=140)\n",
    "\n",
    "def f(ax, idx):\n",
    "    ax.cla()\n",
    "\n",
    "    #plot_pose_3d(ax=ax, tar=tar[idx],\n",
    "    #    #pred=pred,\n",
    "    #    bones=par_data[\"vis\"][\"bones\"], \n",
    "    #    limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "    #    colors=par_data[\"vis\"][\"colors\"],\n",
    "    #    #good_keypts = keypts[idx],\n",
    "    #    normalize=False,\n",
    "    #    legend=True,\n",
    "    #    axes=True)\n",
    "    \n",
    "    plot_pose_2d(\n",
    "        ax, \n",
    "        tar[idx,:,:2], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    "    )\n",
    "    ax.set_xlim([-200,200])\n",
    "    ax.set_ylim([-200,200])\n",
    "    #ax.set_zlim([-40,40])\n",
    "    \n",
    "plot_video_3d(fig, ax, n=2000, fps=20, draw_function=f, name='LiftPose3D_prediction.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acbb6dddb8c49dc895e95e63e237f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.contrib.concurrent import process_map\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "nn = 20\n",
    "frac_samples = 0.25\n",
    "\n",
    "try:\n",
    "    nns_2d, nns_3d = pickle.load(open(par_train['out_dir']+'/neighbors.pkl','rb'))\n",
    "\n",
    "except:   \n",
    "    total = pts3d_target.shape[0]\n",
    "    #poses = [i for i in range(int(frac_samples*total))]\n",
    "    poses = np.random.choice([i for i in range(total)], size=int(frac_samples*total), replace=False)\n",
    "\n",
    "    #3D poses\n",
    "    nns_3d = process_map(partial(find_neighbours, \n",
    "                         pts=pts3d_source, \n",
    "                         target_pts=pts3d_target, \n",
    "                         nn=nn,\n",
    "                         good_keypts=keypts_target), \n",
    "                  poses, max_workers=16)\n",
    "                         \n",
    "    #2D poses\n",
    "    nns_2d = process_map(partial(find_neighbours, \n",
    "                         pts=pts2d_source, \n",
    "                         target_pts=pts2d_target, \n",
    "                         nn=nn), \n",
    "                  poses, max_workers=16)\n",
    "\n",
    "    pickle.dump([poses, nns_2d,nns_3d],open(par_train['out_dir']+'/neighbors.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how much data is needed to generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "poses = np.array(poses)\n",
    "nns_2d = np.array(nns_2d)\n",
    "frac = np.linspace(0.1,1,10)\n",
    "error = []\n",
    "ind = range(len(poses))\n",
    "fold = 10\n",
    "for s in range(fold): #10-fold cross validation\n",
    "    ind_test = random.sample(ind,int(1/fold*len(ind)))\n",
    "    diff = set(ind) - set(ind_test)\n",
    "    \n",
    "    err = []\n",
    "    for f in frac:\n",
    "        ind_train = random.sample(diff,int(f*len(diff)))\n",
    "        A_est_2D = best_linear_map(pts2d_source,pts2d_target[poses[ind_train]],nns_2d[ind_train],nn=5)\n",
    "        pts2d_prism = apply_linear_map(A_est_2D, pts2d_target[poses[ind_test]])\n",
    "        err.append(np.abs(pts2d_source[nns_2d[ind_test][:,:1]] - pts2d_prism).mean())\n",
    "        \n",
    "    error.append(np.array(err))\n",
    "    \n",
    "error = np.array(error)\n",
    "plt.plot(frac*len(poses)*(1-1/fold), error.mean(0)/error.mean(0)[0])\n",
    "plt.ylabel('Normalized distance to nearest neighbor (a.u.)')\n",
    "plt.xlabel('Number of poses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best linear transformation for 2D, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 10\n",
    "nn=10\n",
    "\n",
    "A_est_2D = best_linear_map(pts2d_source, pts2d_target[poses], nns_2d, nn=nn)\n",
    "pts2d_prism = apply_linear_map(A_est_2D, pts2d_target[poses])\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(121)\n",
    "plot_pose_2d(\n",
    "    ax, \n",
    "    pts2d_target[poses[ind]], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    ")\n",
    "ax.set_title('Target domain pose')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "plot_pose_2d(\n",
    "    ax, \n",
    "    pts2d_prism[ind], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    ")\n",
    "ax.set_title('Source domain poses')\n",
    "\n",
    "for i in nns_2d[ind][:nn]:\n",
    "    plot_pose_2d(\n",
    "        ax, \n",
    "        pts2d_source[i], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "        colors=par_data[\"vis\"][\"colors\"], \n",
    "    )\n",
    "    \n",
    "#plt.savefig('2D_mapping.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best linear transformation for 3D, d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 10\n",
    "nn = 10\n",
    "\n",
    "A_est_3D = best_linear_map(pts3d_source,pts3d_target[poses],nns_3d,nn=nn)\n",
    "pts3d_prism = apply_linear_map(A_est_3D, pts3d_target[poses])\n",
    "    \n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "plot_pose_3d(\n",
    "    ax, \n",
    "    pts3d_prism[ind], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    "    good_keypts=None\n",
    ")\n",
    "for i in nns_3d[ind][:nn]:\n",
    "    plot_pose_3d(\n",
    "        ax, \n",
    "        pts3d_source[i], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "        colors=par_data[\"vis\"][\"colors\"], \n",
    "        good_keypts=None\n",
    "    )    \n",
    "    \n",
    "#plt.savefig('3D_mapping.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict poses with trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.postprocess import load_test_results\n",
    "from liftpose.main import set_test_data\n",
    "from liftpose.main import test as lp3d_test\n",
    "from liftpose.lifter.utils import filter_data\n",
    "\n",
    "test_3d_gt, test_3d_pred, good_keypts = [], [], []\n",
    "        \n",
    "#normalize test data\n",
    "test_2d, test_3d, stat_2d, stat_3d = set_test_data(par['out_dir'], {'a':pts2d_prism.copy()}, {'a':pts3d_prism.copy()}, {'a':keypts_target.copy()})\n",
    "    \n",
    "#test data on network\n",
    "lp3d_test(par['out_dir'],test_2d, test_3d, keypts_target.copy())\n",
    "    \n",
    "#load statistics and test results\n",
    "gt, pred, _ = load_test_results(par['out_dir'], stat_2d, stat_3d)\n",
    "\n",
    "#filter noise\n",
    "#test_3d_gt = filter_data(test_3d_gt)\n",
    "#test_3d_pred = filter_data(test_3d_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import plot_pose_3d\n",
    "\n",
    "t = 40\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "plot_pose_3d(ax=ax, tar=pred[t], \n",
    "            pred=gt[t],\n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            good_keypts=keypts_target[t],\n",
    "            show_pred_always=True,\n",
    "            legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(121)\n",
    "plot_pose_2d(\n",
    "    ax, \n",
    "    pts2d_target[poses[ind]], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
