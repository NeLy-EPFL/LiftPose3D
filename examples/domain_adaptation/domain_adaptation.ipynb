{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import load_prism\n",
    "import load_tether\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "from imp import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from liftpose.vision_3d import *\n",
    "from liftpose.preprocess import concat_dict, total_frames, remove_dimensions, center_poses\n",
    "from liftpose.plot import plot_pose_3d, plot_pose_2d\n",
    "reload(logging)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.INFO)\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in the source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decleare data parameters\n",
    "par_train = {  'data_dir'       : '/data/LiftPose3D/fly_tether/data_DF3D', # change the path \n",
    "               'out_dir'        : '/data/LiftPose3D/fly_tether/domain_adaptation',\n",
    "               'train_subjects' : [1,2,3,4,5],\n",
    "               'test_subjects'  : [6,7],\n",
    "               'actions'        : ['all'],\n",
    "               'cam_id'         : [2,5]}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# Load 3D data\n",
    "train_3d_source, train_keypts, rcams_train = load_tether.load_3D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"train_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "\n",
    "test_3d_source, test_keypts, rcams_test = load_tether.load_3D(\n",
    "    par[\"data_dir\"],\n",
    "    par,\n",
    "    cam_id=par[\"cam_id\"],\n",
    "    subjects=par[\"test_subjects\"],\n",
    "    actions=par[\"actions\"],\n",
    ")\n",
    "\n",
    "#remove certain dims to have the same keypoints in source and target domains \n",
    "train_3d_source = remove_dimensions(train_3d_source, [15,16,17,18,34,35,36,37])\n",
    "test_3d_source = remove_dimensions(test_3d_source, [15,16,17,18,34,35,36,37])\n",
    "\n",
    "#center poses\n",
    "train_3d_source = center_poses(train_3d_source)\n",
    "test_3d_source = center_poses(test_3d_source)\n",
    "\n",
    "#project to ventral view\n",
    "train_2d_source = process_dict(project_to_eangle, train_3d_source, 1, [-90,0,0], axsorder='xzy', project=True, intr=None)\n",
    "train_3d_source = process_dict(project_to_eangle, train_3d_source, 1, [-90,0,0], axsorder='xzy')\n",
    "test_2d_source = process_dict(project_to_eangle, test_3d_source, 1, [-90,0,0], axsorder='xzy', project=True, intr=None)\n",
    "test_3d_source = process_dict(project_to_eangle, test_3d_source, 1, [-90,0,0], axsorder='xzy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data in the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decleare data parameters\n",
    "par_train = {'data_dir'       : \"/data/LiftPose3D/fly_prism/data_oriented/training_data\", # change the path \n",
    "             \"train_subjects\" : [\"001\", \"002\", \"003\"],\n",
    "             'test_subjects'  : [\"004\"],\n",
    "             'actions'        : ['PR']}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# load data\n",
    "train_3d_target, train_keypts, _ = load_prism.load_3D(par[\"data_dir\"], \n",
    "                                            subjects=par['train_subjects'], \n",
    "                                            actions=par['actions'])\n",
    "\n",
    "test_3d_target,  test_keypts, _ = load_prism.load_3D( par[\"data_dir\"], \n",
    "                                           subjects=par['test_subjects'],  \n",
    "                                           actions=par['actions'])\n",
    "\n",
    "#center poses\n",
    "train_3d_target = center_poses(train_3d_target)\n",
    "test_3d_target = center_poses(test_3d_target)\n",
    "\n",
    "#project data to ventral view\n",
    "train_2d_target = XY_coord_dict(train_3d_target)\n",
    "test_2d_target = XY_coord_dict(test_3d_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train linear transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ae938f944a487a9a799e7c446b66c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa16770815b4f6e8895338828a7b7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn = 10\n",
    "frac_samples = 0.01\n",
    "\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from functools import partial\n",
    "    \n",
    "total = total_frames(train_3d_target)\n",
    "#poses = [i for i in range(int(frac_samples*total))]\n",
    "poses = np.random.choice([i for i in range(total)], size=int(frac_samples*total), replace=False)\n",
    "\n",
    "#2D poses\n",
    "nns_2d = process_map(partial(find_neighbours, \n",
    "                          pts=concat_dict(train_2d_source), \n",
    "                          target_pts=concat_dict(train_2d_target), \n",
    "                          nn=nn), \n",
    "                  poses, max_workers=16)\n",
    "\n",
    "#3D poses\n",
    "nns_3d = process_map(partial(find_neighbours, \n",
    "                          pts=concat_dict(train_3d_source), \n",
    "                          target_pts=concat_dict(train_3d_target), \n",
    "                          nn=nn), \n",
    "                  poses, max_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best linear transformation for 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_est_2D = best_linear_map(concat_dict(train_2d_source),concat_dict(train_2d_target),nns_2d,nn=2)\n",
    "pts2d_prism = apply_linear_map(A_est_2D, concat_dict(train_2d_target))\n",
    "\n",
    "ind = 2\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plot_pose_2d(\n",
    "    ax, \n",
    "    pts2d_prism[ind], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    colors=par_data[\"vis\"][\"colors\"], \n",
    "    good_keypts=None\n",
    ")\n",
    "for i in nns_2d[ind][:2]:\n",
    "    plot_pose_2d(\n",
    "        ax, \n",
    "        concat_dict(train_2d_source)[i], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "        colors=par_data[\"vis\"][\"colors\"], \n",
    "        good_keypts=None\n",
    "    )\n",
    "    \n",
    "    \n",
    "#plt.savefig('2D_mapping.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best linear transformation for 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "A_est_3D = best_linear_map(concat_dict(train_3d_source),concat_dict(train_3d_target),nns_3d,nn=2)\n",
    "pts3d_prism = apply_linear_map(A_est_3D, concat_dict(train_3d_source))\n",
    "\n",
    "t = 2\n",
    "    \n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "plot_pose_3d(\n",
    "    ax, \n",
    "    pts3d_prism[ind], \n",
    "    bones=par_data[\"vis\"][\"bones\"], \n",
    "    limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "    #colors=par_data[\"vis\"][\"colors\"], \n",
    "    good_keypts=None\n",
    ")\n",
    "for i in nns_3d[ind][:2]:\n",
    "    plot_pose_3d(\n",
    "        ax, \n",
    "        concat_dict(train_3d_source)[i], \n",
    "        bones=par_data[\"vis\"][\"bones\"], \n",
    "        limb_id=par_data[\"vis\"][\"limb_id\"],  \n",
    "        colors=par_data[\"vis\"][\"colors\"], \n",
    "        good_keypts=None\n",
    "    )    \n",
    "    \n",
    "#plt.savefig('3D_mapping.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LiftPose3D Network on DeepFly3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.main import train as lp3d_train\n",
    "from liftpose.lifter.augmentation import add_noise\n",
    "\n",
    "lp3d_train(train_2d=train_2d, test_2d=test_2d,\n",
    "           train_3d=train_3d, test_3d=test_3d, \n",
    "           train_keypts=train_keypts,\n",
    "           test_keypts=test_keypts,\n",
    "           roots=par['roots'],\n",
    "           target_sets=par['target_sets'],\n",
    "           out_dir=par['out_dir'],\n",
    "           network_kwargs={\"epochs\":10},\n",
    "           augmentation=[add_noise(noise_amplitude=.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from liftpose.plot import read_log_train, plot_log_train\n",
    "epoch, lr, loss_train, loss_test, err_test = read_log_train(par['out_dir'])\n",
    "plot_log_train(plt.gca(), loss_train, loss_test, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Trained LiftPose3D Network on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.main import test as lp3d_test\n",
    "lp3d_test(par['out_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liftpose.postprocess import load_test_results\n",
    "data = torch.load(os.path.join(par['out_dir'], \"test_results.pth.tar\"))\n",
    "stat_2d, stat_3d = (\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_2d.pth.tar\")),\n",
    "    torch.load(os.path.join(par['out_dir'], \"stat_3d.pth.tar\")),\n",
    ")\n",
    "test_3d_gt, test_3d_pred, good_keypts = load_test_results(data, stat_2d, stat_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/38865534/7554774\n",
    "# conda install ipympl\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "from liftpose.plot import plot_pose_3d\n",
    "\n",
    "fig = plt.figure(figsize=plt.figaspect(1), dpi=100)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(elev=90, azim=0)\n",
    "\n",
    "t = 0\n",
    "plot_pose_3d(ax=ax, tar=test_3d_gt[t], \n",
    "            pred=test_3d_pred[t], \n",
    "            bones=par_data[\"vis\"][\"bones\"], \n",
    "            limb_id=par_data[\"vis\"][\"limb_id\"], \n",
    "            colors=par_data[\"vis\"][\"colors\"],\n",
    "            good_keypts=good_keypts[t])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
