{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "registered-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load_tether import *\n",
    "import torch\n",
    "import yaml\n",
    "import logging\n",
    "from imp import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from liftpose.vision_3d import world_to_camera_dict, reprojection_error\n",
    "reload(logging)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.INFO)\n",
    "from tqdm import tqdm\n",
    "tqdm.get_lock().locks = []\n",
    "\n",
    "# decleare data parameters\n",
    "par_train = {  'data_dir'       : '/data/LiftPose3D_2602/fly_tether/data_DF3D/', # change the path \n",
    "               'out_dir'        : './out',\n",
    "               'train_subjects' : [1,2,3,4,5],\n",
    "               'test_subjects'  : [6,7],\n",
    "               'actions'        : ['all'],\n",
    "               'cam_id'         : [1]}\n",
    "\n",
    "# merge with training parameter\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "driven-music",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [02:00<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "matplotlib.use('Agg')\n",
    "import utils as utils\n",
    "import transform as transform\n",
    "import stats as stat\n",
    "import plotting as plotting\n",
    "from skeleton import skeleton\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import sys\n",
    "from load_tether import load_3D\n",
    "\n",
    "\n",
    "cameras = [1,5]\n",
    "\n",
    "#import\n",
    "G, color_edge = skeleton() #skeleton\n",
    "legtips = [4, 9, 14, 19, 24, 29]\n",
    "\n",
    "\n",
    "from liftpose.main import test\n",
    "#load data / statistics for cameras\n",
    "out, tar = [], []\n",
    "for cam in cameras:\n",
    "    data_dir = f'out_drop_cam[{cam}]'\n",
    "    \n",
    "    test_3d, _, rcams_test = load_3D(\n",
    "        par[\"data_dir\"],\n",
    "        par,\n",
    "        cam_id=[cam],\n",
    "        subjects=par[\"test_subjects\"],\n",
    "        actions=par[\"actions\"],\n",
    "    )\n",
    "    tar_mean = torch.load(os.path.join(par[\"data_dir\"], 'stat_3d.pth.tar'))['mean']\n",
    "    tar_std = torch.load(os.path.join(par[\"data_dir\"], 'stat_3d.pth.tar'))['std']\n",
    "    targets_3d = torch.load(os.path.join(par[\"data_dir\"], 'stat_3d.pth.tar'))['targets_3d']\n",
    "    offset = torch.load(os.path.join(par[\"data_dir\"], 'stat_3d.pth.tar'))['offset']\n",
    "    offset = np.concatenate([v for k,v in offset.items()], 0)\n",
    "    \n",
    "    #load predictions\n",
    "    data = torch.load(os.path.join(par[\"data_dir\"], '/test_results.pth.tar'))\n",
    "    tar_ = data['target']\n",
    "    out_ = data['output']\n",
    "    \n",
    "    #expand\n",
    "    tar_ = utils.add_roots(tar_, targets_3d, len(tar_mean))\n",
    "    out_ = utils.add_roots(out_, targets_3d, len(tar_mean))\n",
    "    \n",
    "    #unnormalise\n",
    "    tar_ = stat.unNormalize(tar_, tar_mean, tar_std) \n",
    "    out_ = stat.unNormalize(out_, tar_mean, tar_std)\n",
    "    \n",
    "    #translate legs back to their original places\n",
    "    tar_ += offset[0,:]\n",
    "    out_ += offset[0,:]\n",
    "    \n",
    "    #transform back to worldcamera_to_world( poses_cam, cam_par, cam )\n",
    "    tar_ = transform.camera_to_world(tar_, list(rcams_test.values())[11])\n",
    "    out_ = transform.camera_to_world(out_, list(rcams_test.values())[11])\n",
    "    \n",
    "    #tar_ = utils.filter_data(tar_, window=5, order=2)\n",
    "    #out_ = utils.filter_data(out_, window=5, order=2)\n",
    "    \n",
    "    tar.append(tar_)\n",
    "    out.append(out_)\n",
    "\n",
    "#combine cameras\n",
    "#tar = average_cameras(tar)\n",
    "#out = average_cameras(out)\n",
    "tar = np.concatenate(tar, axis=1)\n",
    "out = np.concatenate(out, axis=1)\n",
    "\n",
    "# Set up a figure\n",
    "fig = plt.figure(figsize=plt.figaspect(1))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.view_init(elev=30, azim=25)\n",
    "\n",
    "writer = FFMpegWriter(fps=10)\n",
    "with writer.saving(fig, \"LiftPose3D_prediction_fly_tether_MDN.mp4\", 100):\n",
    "    for t in tqdm(range(55838, 55838 + 900)):\n",
    "        pos_pred, pos_tar = [], []\n",
    "        \n",
    "        ax.cla()\n",
    "        \n",
    "        thist = 7\n",
    "        pos_pred, pos_tar = [], []\n",
    "        for j in range(out.shape[1]//3):\n",
    "            tmin = max(0,t-thist+1)\n",
    "            pos_pred.append((out[tmin:(t+1), 3*j], out[tmin:(t+1), 3*j+1], out[tmin:(t+1), 3*j+2]))\n",
    "            pos_tar.append((tar[tmin:(t+1), 3*j], tar[tmin:(t+1), 3*j+1], tar[tmin:(t+1), 3*j+2]))\n",
    "        pos_pred, pos_tar = np.array(pos_pred), np.array(pos_tar)\n",
    "\n",
    "        pos_tar = rotate_points3d(pos_tar.transpose(2,0,1)).transpose(1,2,0)\n",
    "        pos_pred = rotate_points3d(pos_pred.transpose(2,0,1)).transpose(1,2,0)\n",
    "\n",
    "        plotting.plot_trailing_points(pos_pred[legtips,:,:],min(thist,t+1),ax)\n",
    "        \n",
    "        #plot skeleton\n",
    "        plotting.plot_3d_graph(G, pos_tar[:,:,-1], ax, color_edge=color_edge)    \n",
    "        plotting.plot_3d_graph(G, pos_pred[:,:,-1], ax, color_edge=color_edge, style='--')\n",
    "            \n",
    "        #### this bit is just to make special legend \n",
    "        pts = np.array([1,1])\n",
    "        p1, = ax.plot(pts, pts, pts, 'r-')\n",
    "        p2, = ax.plot(pts, pts, pts, 'b-')\n",
    "        p3, = ax.plot(pts, pts, pts, 'r--', dashes=(2, 2))\n",
    "        p4, = ax.plot(pts, pts, pts, 'b--', dashes=(2, 2))\n",
    "        ax.legend([(p1, p2), (p3, p4)], \n",
    "            ['Triangulated 3D pose using 3 cameras per keypoint', \\\n",
    "             'LiftPose3D prediction using 1 camera per keypoint'], \n",
    "            numpoints=1, handler_map={tuple: HandlerTuple(ndivide=None)},\n",
    "            loc=(0.1,0.9),\n",
    "            frameon=False)    \n",
    "        p1.remove()\n",
    "        p2.remove()\n",
    "        p3.remove()\n",
    "        p4.remove()\n",
    "        ####    \n",
    "           \n",
    "        #ax.set_xlim([-2,5])\n",
    "        #ax.set_ylim([-1,4])\n",
    "        #ax.set_zlim([1,2.75])\n",
    "        \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "        ax.grid(True)\n",
    "        \n",
    "        writer.grab_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "necessary-yahoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3.1 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1609680890771/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1609680890771/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1609680890771/_build_env/bin/pkg-config\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'DeepFly3D_prediction_fly_tether_MDN.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "  Duration: 00:01:30.00, start: 0.000000, bitrate: 4575 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 960x960, 4574 kb/s, 10 fps, 10 tbr, 10240 tbn, 20 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from 'LiftPose3D_prediction_fly_tether_MDN.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "  Duration: 00:01:30.00, start: 0.000000, bitrate: 327 kb/s\n",
      "    Stream #1:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 400x400, 326 kb/s, 10 fps, 10 tbr, 10240 tbn, 20 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> scale\n",
      "  Stream #1:0 (h264) -> hstack:input1\n",
      "  hstack -> Stream #0:0 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mprofile High, level 2.2, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0m264 - core 161 r3030M 8bd6d28 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'Video_1.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 800x400, q=-1--1, 10 fps, 10240 tbn, 10 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.91.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  900 fps=422 q=-1.0 Lsize=    5133kB time=00:01:29.70 bitrate= 468.8kbits/s speed=  42x    \n",
      "video:5122kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.222142%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mframe I:4     Avg QP:16.54  size: 46474\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mframe P:230   Avg QP:21.16  size: 10963\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mframe B:666   Avg QP:25.02  size:  3809\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mconsecutive B-frames:  0.4%  1.6%  3.3% 94.7%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mmb I  I16..4: 16.9% 36.0% 47.2%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mmb P  I16..4:  0.7%  1.9%  2.6%  P16..4: 24.9% 18.5% 14.7%  0.0%  0.0%    skip:36.6%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mmb B  I16..4:  0.1%  0.4%  0.4%  B16..8: 28.5% 11.6%  4.9%  direct: 1.8%  skip:52.3%  L0:46.3% L1:46.4% BI: 7.3%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0m8x8 transform intra:37.7% inter:51.2%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mcoded y,uvDC,uvAC intra: 57.5% 34.6% 31.1% inter: 13.1% 5.0% 4.4%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mi16 v,h,dc,p: 55% 22% 21%  3%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 15% 41%  5%  6%  5%  6%  5%  6%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 13% 21%  8%  6%  6% 10%  4%  4%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mi8c dc,h,v,p: 79%  9% 10%  2%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mref P L0: 53.2%  8.9% 24.1% 13.8%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mref B L0: 78.3% 16.3%  5.5%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mref B L1: 92.2%  7.8%\n",
      "\u001b[1;36m[libx264 @ 0x564b5588ce00] \u001b[0mkb/s:466.15\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i DeepFly3D_prediction_fly_tether_MDN.mp4 -i LiftPose3D_prediction_fly_tether_MDN.mp4 -filter_complex \"[0:v]scale=-1:400[v0];[v0][1:v]hstack=inputs=2\" Video_1.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
