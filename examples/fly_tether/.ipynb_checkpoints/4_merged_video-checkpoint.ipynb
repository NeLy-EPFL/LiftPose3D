{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from skeleton import skeleton\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "import matplotlib\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = '180919_MDN_CsCh_Fly6_001_SG1_behData_images'\n",
    "root_folder = '/data/LiftFly3D/DF3D/data_DF3D/'\n",
    "dims_to_consider = [i for i in range(38) if i not in [15,16,17,18,34,35,36,37]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 2D stacked hourglass prediction on images and save as a 25fps video (4x slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 900, 30, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G, color_edge = skeleton()\n",
    "poses = pickle.load(open(root_folder + 'pose_result__data_paper_' + experiment + '.pkl', \"rb\"))\n",
    "poses = poses['points2d']\n",
    "poses = poses[:,:,dims_to_consider,:]\n",
    "poses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/LiftFly3D/DF3D/data_DF3D/180919_MDN_CsCh_Fly6_001_SG1_behData_images/camera_1*.jpg\n"
     ]
    }
   ],
   "source": [
    "cam=1 #5 #run twice for cam 1 and 5\n",
    "\n",
    "#load images\n",
    "files = glob.glob(root_folder + experiment + '/' + 'camera_' + str(cam) + '*.jpg')\n",
    "imgs = []\n",
    "for f in sorted(files):\n",
    "    img = cv2.imread(f)\n",
    "    imgs.append(img)\n",
    "    \n",
    "assert imgs != [], 'no files found'    \n",
    "\n",
    "#filter\n",
    "poses2d = poses[cam,:,:,:]\n",
    "poses2d = np.reshape(poses2d, (poses2d.shape[0], poses2d.shape[1]*poses2d.shape[2]))\n",
    "poses2d = utils.filter_data(poses2d, window=5, order=2)\n",
    "\n",
    "fig = plt.figure(figsize=(9.6,4.8))\n",
    "print(root_folder + experiment + '/' + 'camera_' + str(cam) + '*.jpg')\n",
    "\n",
    "writer = FFMpegWriter(fps=10)\n",
    "with writer.saving(fig, root_folder + \"/camera_\" + str(cam) + \".mp4\", 100):\n",
    "    for t in range(poses.shape[1]):\n",
    "        plt.cla()\n",
    "        \n",
    "        plt.imshow(imgs[t])\n",
    "        \n",
    "        for i, j in enumerate(G.edges()): \n",
    "            x = np.array((poses2d[t,2*j[0]], poses2d[t,2*j[1]]))\n",
    "            y = np.array((poses2d[t,2*j[0]+1], poses2d[t,2*j[1]+1]))\n",
    "                   \n",
    "            plt.plot(x, y, c=color_edge[j[0]], alpha=1.0, linewidth = 2)\n",
    "            #opto stimulation indicator circle\n",
    "            if (t >= 100) & (t<800):\n",
    "                plt.scatter(900,50, marker = \"o\", c='C1', s = 500)\n",
    "            \n",
    "        plt.axis('off')\n",
    "        fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "        \n",
    "        writer.grab_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create video_1.mp4, execute these commands in sequence in the folder where the videos are\n",
    "\n",
    "#stack videos vertically (call this in the folder where the images are)\n",
    "#ffmpeg -i camera_1.mp4 -i camera_5.mp4 -filter_complex vstack=inputs=2 stacked.mp4\n",
    "\n",
    "#annotate\n",
    "#ffmpeg -i stacked.mp4 -vf drawtext=\"fontfile=/home/gosztolai/Dropbox/github/fly_data_analysis/Liftfly3D/DF3D/src/helvetica.ttf: text='Camera 2': fontcolor=white: fontsize=80: x=1*(w-text_w)/10: y=1*(h-text_h)/10/2\" -codec:a copy stacked_b.mp4\n",
    "#ffmpeg -i stacked_b.mp4 -vf drawtext=\"fontfile=/home/gosztolai/Dropbox/github/fly_data_analysis/Liftfly3D/DF3D/src/helvetica.ttf: text='Camera 5': fontcolor=white: fontsize=80: x=1*(w-text_w)/10: y=6*(h-text_h)/10\" -codec:a copy stacked_2b.mp4\n",
    "\n",
    "#stack videos horizontally (call this in the folder where the images are)\n",
    "#ffmpeg -i stacked_2b.mp4 -i prediction_cams.mp4 -filter_complex \"[0:v]scale=-1:480[v0];[v0][1:v]hstack=inputs=2\" video_1.mp4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
