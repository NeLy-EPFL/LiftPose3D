{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train using prism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from load import load_3D\n",
    "from liftpose.vision_3d import XY_coord, Z_coord\n",
    "import yaml\n",
    "import logging\n",
    "from imp import reload\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "reload(logging)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.INFO)\n",
    "\n",
    "# decleare data parameters\n",
    "par_train = {'data_dir'     : \"/data/LiftPose3D/fly_ventral_highres/network\", # change the path \n",
    "             \"template_dir\" : '/home/user/Desktop/LiftPose3D/examples/fly_prism/out/',\n",
    "           'out_dir'        : './out',\n",
    "            \"train_subjects\": [\"001\", \"002\", \"003\"],\n",
    "           'test_subjects'  : [\"004\"],\n",
    "           'actions'        : ['PR']}\n",
    "\n",
    "# merge with training parameters\n",
    "par_data = yaml.full_load(open('param.yaml', \"rb\"))\n",
    "par = {**par_data[\"data\"], **par_train}\n",
    "\n",
    "# load data\n",
    "train, train_keypts, _ = load_3D(par[\"data_dir\"], subjects=par['train_subjects'], actions=par['actions'] )\n",
    "test,  test_keypts, _ = load_3D(par[\"data_dir\"], subjects=par['test_subjects'],  actions=par['actions'] )\n",
    "#project data to ventral view\n",
    "train_2d, train_3d = XY_coord(train), Z_coord(train)\n",
    "test_2d, test_3d  = XY_coord(test), Z_coord(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main.py:79]:INFO:Creating directory /home/user/Desktop/LiftPose3D/examples/fly_ventral_highres/out\n",
      "[main.py:89]:INFO:Saving pre-processed 2D data at /home/user/Desktop/LiftPose3D/examples/fly_ventral_highres/out/stat_2d.pth.tar.\n",
      "[main.py:111]:INFO:Saving pre-processed 3D data at /home/user/Desktop/LiftPose3D/examples/fly_ventral_highres/out/stat_3d.pth.tar.\n",
      "[main.py:138]:INFO:Starting training model\n",
      "[main.py:147]:DEBUG:\n",
      "==================Options=================\n",
      "[main.py:148]:DEBUG:{   'batch_size': 64,\n",
      "    'data_dir': '/home/user/Desktop/LiftPose3D/examples/fly_ventral_highres/out',\n",
      "    'dropout': 0.5,\n",
      "    'epochs': 10,\n",
      "    'exp': '',\n",
      "    'is_train': True,\n",
      "    'job': 8,\n",
      "    'linear_size': 1024,\n",
      "    'load': None,\n",
      "    'lr': 0.001,\n",
      "    'lr_decay': 100000,\n",
      "    'lr_gamma': 0.96,\n",
      "    'max_norm': True,\n",
      "    'noise': None,\n",
      "    'num_stage': 2,\n",
      "    'out': '/home/user/Desktop/LiftPose3D/examples/fly_ventral_highres/out',\n",
      "    'out_dir': '/home/user/Desktop/LiftPose3D/examples/fly_ventral_highres/out',\n",
      "    'predict': False,\n",
      "    'procrustes': False,\n",
      "    'resume': False,\n",
      "    'test': False}\n",
      "[main.py:149]:DEBUG:==========================================\n",
      "\n",
      "[lift.py:54]:INFO:total params: 4.28M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss Test 0 | Loss Train 1.3467|: 100%|██████████| 161/161 [00:02<00:00, 66.58it/s]\n",
      "Epoch 1 | Loss Test 1.0519 | Loss Train 0.40511|: 100%|██████████| 161/161 [00:02<00:00, 66.77it/s]\n",
      "Epoch 2 | Loss Test 0.95733 | Loss Train 0.139|: 100%|██████████| 161/161 [00:01<00:00, 82.26it/s]  \n",
      "Epoch 3 | Loss Test 0.75994 | Loss Train 0.061662|: 100%|██████████| 161/161 [00:02<00:00, 79.81it/s] \n",
      "Epoch 4 | Loss Test 0.74613 | Loss Train 0.037966|: 100%|██████████| 161/161 [00:02<00:00, 70.46it/s]\n",
      "Epoch 5 | Loss Test 0.71244 | Loss Train 0.031539|: 100%|██████████| 161/161 [00:02<00:00, 69.71it/s]\n",
      "Epoch 6 | Loss Test 0.70805 | Loss Train 0.027766|: 100%|██████████| 161/161 [00:01<00:00, 88.53it/s]\n",
      "Epoch 7 | Loss Test 0.68022 | Loss Train 0.026031|: 100%|██████████| 161/161 [00:02<00:00, 79.82it/s]\n",
      "Epoch 8 | Loss Test 0.66295 | Loss Train 0.024374|: 100%|██████████| 161/161 [00:02<00:00, 67.85it/s]\n",
      "Epoch 9 | Loss Test 0.67225 | Loss Train 0.022938|: 100%|██████████| 161/161 [00:02<00:00, 73.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from liftpose.main import train as lp3d_train\n",
    "lp3d_train(train_2d=train_2d, test_2d=test_2d, train_3d=train_3d, test_3d=test_3d, \n",
    "           train_keypts=train_keypts, test_keypts=test_keypts, \n",
    "           **{k:par[k] for k in ['roots', 'target_sets', 'out_dir']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from liftpose.preprocess import *\n",
    "from liftpose.main import flatten_dict\n",
    "def create_xy_data( par ):\n",
    "    \"\"\"\n",
    "    Creates 2d poses by projecting 3d poses with the corresponding camera\n",
    "    parameters.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    test_set, _, _ = load_3D(par['data_dir'], par, subjects=par['test_subjects'], actions=par['actions'] )\n",
    "    test_set = flatten_dict(test_set)\n",
    "\n",
    "    # anchor points\n",
    "    test_set, _ = anchor_to_root( test_set, par['roots'], par['target_sets'], dim=2)    \n",
    "\n",
    "    # Compute normalization statistics\n",
    "    mean = torch.load(par['template_dir'] + 'stat_2d.pth.tar')['mean']\n",
    "    std = torch.load(par['template_dir'] + 'stat_2d.pth.tar')['std']\n",
    "\n",
    "    refs = np.array(par['template_coords']).astype(int)\n",
    "    refs = np.sort(np.hstack((refs*2, refs*2+1)))\n",
    "    \n",
    "    # Divide every dimension independently\n",
    "    test_set = normalize(test_set, mean[refs], std[refs] )\n",
    "\n",
    "    #select coordinates to be predicted and return them as 'targets_3d'\n",
    "    test_set, targets_2d = remove_roots(test_set, par['target_sets'], 2)\n",
    "    _, targets_1d = remove_roots(test_set.copy(), par['target_sets'], 1)\n",
    "\n",
    "    return test_set, mean, std, targets_1d, targets_2d\n",
    "\n",
    "\n",
    "par = {'data_dir': '/data/LiftPose3D/fly_ventral_lowres/102906_s1a5_p6-0/',\n",
    "'template_dir': '/home/user/Desktop/LiftPose3D/examples/fly_prism/out/',\n",
    "'out_dir':'./out/',\n",
    "'in_dim': 2,\n",
    "'out_dim': 1,\n",
    "'test_subjects': [0],\n",
    "'actions': ['all'], #actions to load\n",
    "'target_sets': [[ 1,  2,  3],  [5,  6,  7], [9, 10, 11],\n",
    "               [13, 14, 15], [17, 18, 19], [21, 22, 23]],\n",
    "'roots': [0, 4, 8, 12, 16, 20],\n",
    "'template_coords': [ 1,2,3,4,   6,7,8,9,  11,12,13,14, #coordinates in the prism system\n",
    "                  16,17,18,19,  21,22,23,24,  26,27,28,29]}\n",
    "\n",
    "test_set, mean, std, targets_1d, targets_2d = \\\n",
    "create_xy_data(par)\n",
    "\n",
    "torch.save(test_set, par['out_dir'] + '/test_2d.pth.tar')\n",
    "torch.save({'mean': mean, 'std': std, \n",
    "            'targets_2d': targets_1d, 'targets_3d': targets_2d,\n",
    "            'input_size': len(targets_2d),\n",
    "            'output_size': len(targets_1d)},\n",
    "            par['out_dir'] + '/stat_2d.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main.py:154]:INFO:starting testing in path: ./out/\n",
      "[lift.py:54]:INFO:total params: 4.28M\n",
      "[lift.py:60]:INFO:loading ckpt from './out//ckpt_best.pth.tar'\n",
      "[lift.py:68]:INFO:ckpt loaded (epoch: 8 | err: 2.041229486465454)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [64 x 36], m2: [48 x 1024] at /opt/conda/conda-bld/pytorch_1591914895884/work/aten/src/THC/generic/THCTensorMathBlas.cu:283",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3df7ef457a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mliftpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlp3d_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlp3d_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/LiftPose3D/liftpose/main.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(out_dir)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/ckpt_best.pth.tar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mnetwork_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/LiftPose3D/liftpose/lifter/lift.py\u001b[0m in \u001b[0;36mnetwork_main\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mgood_keypts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         ) = test(test_loader, model, criterion, stat_3d, predict=opt.predict)\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/Desktop/LiftPose3D/liftpose/lifter/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_loader, model, criterion, stat, predict)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mall_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lf3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/LiftPose3D/liftpose/lifter/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# pre-processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lf3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lf3d/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lf3d/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [64 x 36], m2: [48 x 1024] at /opt/conda/conda-bld/pytorch_1591914895884/work/aten/src/THC/generic/THCTensorMathBlas.cu:283"
     ]
    }
   ],
   "source": [
    "from liftpose.main import test as lp3d_test\n",
    "lp3d_test(par['out_dir'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
